{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "300afcee",
   "metadata": {},
   "source": [
    "# BERT Token Classification for Italian Term Extraction\n",
    "\n",
    "This notebook demonstrates a BERT-based approach to term extraction:\n",
    "- Uses BIO tagging scheme (Beginning-Inside-Outside)\n",
    "- Fine-tunes Italian BERT model for token classification\n",
    "- Trains on labeled data to recognize term boundaries\n",
    "\n",
    "Dataset: EvalITA 2025 ATE-IT (Automatic Term Extraction - Italian Testbed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257d342c",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bacd6f61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T10:43:33.424051Z",
     "start_time": "2025-11-11T10:42:33.407768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete\n",
      "PyTorch version: 2.8.0+cpu\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer, #choose this\n",
    "    AutoModelForTokenClassification,  #choose this\n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    DataCollatorForTokenClassification\n",
    ")\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Setup complete\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8767bd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['O', 'B-TERM', 'I-TERM']\n",
      "Label to ID: {'O': 0, 'B-TERM': 1, 'I-TERM': 2}\n",
      "\n",
      "Model: dbmdz/bert-base-italian-uncased\n",
      "Output directory: models/bert_token_classification_2e-5_changed\n"
     ]
    }
   ],
   "source": [
    "# Define label mappings for BIO tagging scheme\n",
    "label_list = ['O', 'B-TERM', 'I-TERM']\n",
    "label2id = {k: v for v, k in enumerate(label_list)}\n",
    "id2label = {v: k for v, k in enumerate(label_list)}\n",
    "\n",
    "print(f\"Labels: {label_list}\")\n",
    "print(f\"Label to ID: {label2id}\")\n",
    "\n",
    "# Model configuration\n",
    "model_name = \"dbmdz/bert-base-italian-cased-wwm\" # for everything before: bert-base-italian-uncased\n",
    "output_model_dir = \"models/bert_token_classification_3e-5_changed\" #TODO CHANHGE\n",
    "\n",
    "print(f\"\\nModel: {model_name}\")\n",
    "print(f\"Output directory: {output_model_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8142a69c",
   "metadata": {},
   "source": [
    "## Data Loading and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dfe3bbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "def load_jsonl(path: str):\n",
    "    \"\"\"Load a JSON lines file or JSON array file.\"\"\"\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read().strip()\n",
    "    if not text:\n",
    "        return []\n",
    "    try:\n",
    "        data = json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        data = []\n",
    "        for line in text.splitlines():\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "#aggregate the terms concatenating the paragraphs\n",
    "def build_sentence_gold_map(records):\n",
    "    \"\"\"Convert dataset rows into list of sentences with aggregated terms.\"\"\"\n",
    "    out = {}\n",
    "    \n",
    "    if isinstance(records, dict) and 'data' in records:\n",
    "        rows = records['data']\n",
    "    else:\n",
    "        rows = records\n",
    "    \n",
    "    for r in rows:\n",
    "        key = (r.get('document_id'), r.get('paragraph_id'), r.get('sentence_id'))\n",
    "        if key not in out:\n",
    "            out[key] = {\n",
    "                'document_id': r.get('document_id'),\n",
    "                'paragraph_id': r.get('paragraph_id'),\n",
    "                'sentence_id': r.get('sentence_id'),\n",
    "                'sentence_text': r.get('sentence_text', ''),\n",
    "                'terms': []\n",
    "            }\n",
    "        \n",
    "        if isinstance(r.get('term_list'), list):\n",
    "            for t in r.get('term_list'):\n",
    "                if t and t not in out[key]['terms']:\n",
    "                    out[key]['terms'].append(t)\n",
    "        else:\n",
    "            term = r.get('term')\n",
    "            if term and term not in out[key]['terms']:\n",
    "                out[key]['terms'].append(term)\n",
    "    \n",
    "    return list(out.values())\n",
    "\n",
    "\n",
    "print(\"✓ Data loading functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05486208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sentences: 2308\n",
      "Dev sentences: 577\n",
      "\n",
      "Example sentence:\n",
      "  Text: AFFIDAMENTO DEL “SERVIZIO DI SPAZZAMENTO, RACCOLTA, TRASPORTO E SMALTIMENTO/RECUPERO DEI RIFIUTI URBANI ED ASSIMILATI E SERVIZI COMPLEMENTARI DELLA CITTA' DI AGROPOLI” VALEVOLE PER UN QUINQUENNIO\n",
      "  Terms: ['raccolta', 'recupero', 'servizio di raccolta', 'servizio di spazzamento', 'smaltimento', 'trasporto']\n"
     ]
    }
   ],
   "source": [
    "# Load training and dev data\n",
    "train_data = load_jsonl('../data/subtask_a_train.json')\n",
    "dev_data = load_jsonl('../data/subtask_a_dev.json')\n",
    "\n",
    "train_sentences = build_sentence_gold_map(train_data)\n",
    "dev_sentences = build_sentence_gold_map(dev_data)\n",
    "\n",
    "print(f\"Training sentences: {len(train_sentences)}\")\n",
    "print(f\"Dev sentences: {len(dev_sentences)}\")\n",
    "print(f\"\\nExample sentence:\")\n",
    "print(f\"  Text: {train_sentences[6]['sentence_text']}\")\n",
    "print(f\"  Terms: {train_sentences[6]['terms']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f56f629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, force_lower=True):\n",
    "    # fix encoding issues\n",
    "    text = text.replace(\"\\u00a0\", \" \")\n",
    "\n",
    "    # normalize spaces\n",
    "    text = \" \".join(text.split())\n",
    "\n",
    "    # unify apostrophes\n",
    "    text = text.replace(\"’\", \"'\").replace(\"`\", \"'\")\n",
    "\n",
    "    # lowercase if model is uncased\n",
    "    if force_lower:\n",
    "        text = text.lower()\n",
    "\n",
    "    # remove weird control characters\n",
    "    text = \"\".join(c for c in text if c.isprintable())\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b9e0c703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sentences: 2308\n",
      "Dev sentences: 577\n",
      "\n",
      "Example sentence:\n",
      "  Text: affidamento del “servizio di spazzamento, raccolta, trasporto e smaltimento/recupero dei rifiuti urbani ed assimilati e servizi complementari della citta' di agropoli” valevole per un quinquennio\n",
      "  Terms: ['raccolta', 'recupero', 'servizio di raccolta', 'servizio di spazzamento', 'smaltimento', 'trasporto']\n"
     ]
    }
   ],
   "source": [
    "for entry in train_sentences:\n",
    "    # pulisci il testo della frase\n",
    "    entry[\"sentence_text\"] = preprocess_text(entry[\"sentence_text\"])\n",
    "    # (opzionale ma consigliato) pulisci anche i termini gold\n",
    "    entry[\"terms\"] = [preprocess_text(t) for t in entry[\"terms\"]]\n",
    "\n",
    "for entry in dev_sentences:\n",
    "    entry[\"sentence_text\"] = preprocess_text(entry[\"sentence_text\"])\n",
    "    entry[\"terms\"] = [preprocess_text(t) for t in entry[\"terms\"]]\n",
    "\n",
    "print(f\"Training sentences: {len(train_sentences)}\")\n",
    "print(f\"Dev sentences: {len(dev_sentences)}\")\n",
    "print(f\"\\nExample sentence:\")\n",
    "print(f\"  Text: {train_sentences[6]['sentence_text']}\")\n",
    "print(f\"  Terms: {train_sentences[6]['terms']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90654f36",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "Using the official evaluation metrics from the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2708c291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Evaluation functions defined\n"
     ]
    }
   ],
   "source": [
    "def micro_f1_score(gold_standard, system_output):\n",
    "    \"\"\"\n",
    "    Evaluates performance using Precision, Recall, and F1 score \n",
    "    based on individual term matching (micro-average).\n",
    "    \"\"\"\n",
    "    total_true_positives = 0\n",
    "    total_false_positives = 0\n",
    "    total_false_negatives = 0\n",
    "    \n",
    "    for gold, system in zip(gold_standard, system_output):\n",
    "        gold_set = set(gold)\n",
    "        system_set = set(system)\n",
    "        \n",
    "        true_positives = len(gold_set.intersection(system_set))\n",
    "        false_positives = len(system_set - gold_set)\n",
    "        false_negatives = len(gold_set - system_set)\n",
    "        \n",
    "        total_true_positives += true_positives\n",
    "        total_false_positives += false_positives\n",
    "        total_false_negatives += false_negatives\n",
    "    \n",
    "    precision = total_true_positives / (total_true_positives + total_false_positives) if (total_true_positives + total_false_positives) > 0 else 0\n",
    "    recall = total_true_positives / (total_true_positives + total_false_negatives) if (total_true_positives + total_false_negatives) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1, total_true_positives, total_false_positives, total_false_negatives\n",
    "\n",
    "\n",
    "def type_f1_score(gold_standard, system_output):\n",
    "    \"\"\"\n",
    "    Evaluates performance using Type Precision, Type Recall, and Type F1 score\n",
    "    based on the set of unique terms extracted at least once across the entire dataset.\n",
    "    \"\"\"\n",
    "    all_gold_terms = set()\n",
    "    for item_terms in gold_standard:\n",
    "        all_gold_terms.update(item_terms)\n",
    "    \n",
    "    all_system_terms = set()\n",
    "    for item_terms in system_output:\n",
    "        all_system_terms.update(item_terms)\n",
    "    \n",
    "    type_true_positives = len(all_gold_terms.intersection(all_system_terms))\n",
    "    type_false_positives = len(all_system_terms - all_gold_terms)\n",
    "    type_false_negatives = len(all_gold_terms - all_system_terms)\n",
    "    \n",
    "    type_precision = type_true_positives / (type_true_positives + type_false_positives) if (type_true_positives + type_false_positives) > 0 else 0\n",
    "    type_recall = type_true_positives / (type_true_positives + type_false_negatives) if (type_true_positives + type_false_negatives) > 0 else 0\n",
    "    type_f1 = 2 * (type_precision * type_recall) / (type_precision + type_recall) if (type_precision + type_recall) > 0 else 0\n",
    "    \n",
    "    return type_precision, type_recall, type_f1\n",
    "\n",
    "\n",
    "print(\"✓ Evaluation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfac0bc",
   "metadata": {},
   "source": [
    "## Initialize BERT Model and Tokenizer\n",
    "\n",
    "Always load\n",
    "- tokenizer\n",
    "- bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2bb1b27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing BERT tokenizer and model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-italian-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Tokenizer loaded: BertTokenizerFast\n",
      "✓ Model loaded with 3 labels\n",
      "  Vocabulary size: 31102\n"
     ]
    }
   ],
   "source": [
    "# Initialize tokenizer and model\n",
    "print(\"Initializing BERT tokenizer and model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name, \n",
    "    num_labels=len(label_list), #labels we're trying to predict\n",
    "    id2label=id2label, \n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "print(f\"✓ Tokenizer loaded: {tokenizer.__class__.__name__}\")\n",
    "print(f\"✓ Model loaded with {model.num_labels} labels\")\n",
    "print(f\"  Vocabulary size: {tokenizer.vocab_size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681cd148",
   "metadata": {},
   "source": [
    "## BIO Tag Generation for Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "158f6ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing BERT tokenizer and model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-italian-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Tokenizer loaded: BertTokenizerFast\n",
      "✓ Model loaded with 3 labels\n",
      "  Vocabulary size: 31102\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "# Initialize tokenizer and model\n",
    "print(\"Initializing BERT tokenizer and model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name, \n",
    "    num_labels=len(label_list), #labels we're trying to predict\n",
    "    id2label=id2label, \n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "print(f\"✓ Tokenizer loaded: {tokenizer.__class__.__name__}\")\n",
    "print(f\"✓ Model loaded with {model.num_labels} labels\")\n",
    "print(f\"  Vocabulary size: {tokenizer.vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0668cf5c",
   "metadata": {},
   "source": [
    "## Process Training and Dev Data with BIO Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d0b466b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ner_tags(text: str, terms: list[str], tokenizer, label2id: dict):\n",
    "    \"\"\"\n",
    "    Crea token e BIO tag per una frase, dato l'elenco dei termini gold.\n",
    "\n",
    "    text: frase pre-processata (come in preprocess_text)\n",
    "    terms: lista di termini gold pre-processati\n",
    "    tokenizer: tokenizer HuggingFace\n",
    "    label2id: dict, es. {'O': 0, 'B-TERM': 1, 'I-TERM': 2}\n",
    "\n",
    "    Ritorna:\n",
    "        tokens: list[str]\n",
    "        ner_tags: list[int] (stessa lunghezza di tokens)\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 1) Trova tutti gli span (start_char, end_char) dei termini nel testo ---\n",
    "\n",
    "    def is_boundary(ch: str | None) -> bool:\n",
    "        \"\"\"True se il carattere è None o non alfanumerico (quindi buon confine di parola).\"\"\"\n",
    "        if ch is None:\n",
    "            return True\n",
    "        return not ch.isalnum()\n",
    "\n",
    "    spans = []  # lista di (start, end)\n",
    "    for term in terms:\n",
    "        term = term.strip()\n",
    "        if not term:\n",
    "            continue\n",
    "\n",
    "        start = 0\n",
    "        while True:\n",
    "            idx = text.find(term, start)\n",
    "            if idx == -1:\n",
    "                break\n",
    "\n",
    "            end = idx + len(term)\n",
    "\n",
    "            # Controllo confini di parola\n",
    "            before = text[idx - 1] if idx > 0 else None\n",
    "            after = text[end] if end < len(text) else None\n",
    "\n",
    "            if is_boundary(before) and is_boundary(after):\n",
    "                spans.append((idx, end))\n",
    "\n",
    "            start = idx + len(term)\n",
    "\n",
    "    # opzionale: ordina gli span per inizio\n",
    "    spans.sort(key=lambda x: x[0])\n",
    "\n",
    "    # --- 2) Tokenizza con offset mapping ---\n",
    "    encoded = tokenizer(\n",
    "        text,\n",
    "        return_offsets_mapping=True,\n",
    "        add_special_tokens=False\n",
    "    )\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(encoded[\"input_ids\"])\n",
    "    offsets = encoded[\"offset_mapping\"]\n",
    "\n",
    "    ner_tags = [label2id[\"O\"]] * len(tokens)\n",
    "\n",
    "    # --- 3) Assegna BIO tag in base agli span ---\n",
    "    for i, (tok_start, tok_end) in enumerate(offsets):\n",
    "        # alcuni tokenizer possono dare (0, 0) per token speciali, ma noi add_special_tokens=False\n",
    "        if tok_start == tok_end:\n",
    "            ner_tags[i] = label2id[\"O\"]\n",
    "            continue\n",
    "\n",
    "        tag = \"O\"\n",
    "        for span_start, span_end in spans:\n",
    "            # se il token inizia dentro uno span\n",
    "            if tok_start >= span_start and tok_start < span_end:\n",
    "                if tok_start == span_start:\n",
    "                    tag = \"B-TERM\"\n",
    "                else:\n",
    "                    tag = \"I-TERM\"\n",
    "                break\n",
    "\n",
    "        ner_tags[i] = label2id[tag]\n",
    "\n",
    "    return tokens, ner_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f1b6518b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training data...\n",
      "  Processed 0/2308\n",
      "  Processed 1000/2308\n",
      "  Processed 2000/2308\n",
      "✓ Training data processed: 2308 sentences\n",
      "\n",
      "Processing dev data...\n",
      "  Processed 0/577\n",
      "  Processed 200/577\n",
      "  Processed 400/577\n",
      "✓ Dev data processed: 577 sentences\n",
      "\n",
      "Sample train sentence:\n",
      "  Text: affidamento del “servizio di spazzamento, raccolta, trasporto e smaltimento/recupero dei rifiuti urbani ed assimilati e servizi complementari della citta' di agropoli” valevole per un quinquennio\n",
      "  Terms: ['raccolta', 'recupero', 'servizio di raccolta', 'servizio di spazzamento', 'smaltimento', 'trasporto']\n",
      "\n",
      "|    | Token         | Tag    |\n",
      "|---:|:--------------|:-------|\n",
      "|  0 | affidamento   | O      |\n",
      "|  1 | del           | O      |\n",
      "|  2 | “             | O      |\n",
      "|  3 | servizio      | B-TERM |\n",
      "|  4 | di            | I-TERM |\n",
      "|  5 | spa           | I-TERM |\n",
      "|  6 | ##zzamento    | I-TERM |\n",
      "|  7 | ,             | O      |\n",
      "|  8 | raccolta      | B-TERM |\n",
      "|  9 | ,             | O      |\n",
      "| 10 | trasporto     | B-TERM |\n",
      "| 11 | e             | O      |\n",
      "| 12 | smaltimento   | B-TERM |\n",
      "| 13 | /             | O      |\n",
      "| 14 | recupero      | B-TERM |\n",
      "| 15 | dei           | O      |\n",
      "| 16 | rifiuti       | O      |\n",
      "| 17 | urbani        | O      |\n",
      "| 18 | ed            | O      |\n",
      "| 19 | assimi        | O      |\n",
      "| 20 | ##lati        | O      |\n",
      "| 21 | e             | O      |\n",
      "| 22 | servizi       | O      |\n",
      "| 23 | complementari | O      |\n",
      "| 24 | della         | O      |\n",
      "| 25 | citta         | O      |\n",
      "| 26 | '             | O      |\n",
      "| 27 | di            | O      |\n",
      "| 28 | agro          | O      |\n",
      "| 29 | ##poli        | O      |\n",
      "| 30 | ”             | O      |\n",
      "| 31 | vale          | O      |\n",
      "| 32 | ##vole        | O      |\n",
      "| 33 | per           | O      |\n",
      "| 34 | un            | O      |\n",
      "| 35 | quinqu        | O      |\n",
      "| 36 | ##ennio       | O      |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Process training data\n",
    "print(\"Processing training data...\")\n",
    "for i, entry in enumerate(train_sentences):\n",
    "    text = entry['sentence_text']\n",
    "    terms = entry['terms']\n",
    "    \n",
    "    tokens, ner_tags = create_ner_tags(text, terms, tokenizer, label2id)\n",
    "    entry['tokens'] = tokens\n",
    "    entry['ner_tags'] = ner_tags\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print(f\"  Processed {i}/{len(train_sentences)}\")\n",
    "\n",
    "print(f\"✓ Training data processed: {len(train_sentences)} sentences\")\n",
    "\n",
    "# Process dev data\n",
    "print(\"\\nProcessing dev data...\")\n",
    "for i, entry in enumerate(dev_sentences):\n",
    "    text = entry['sentence_text']\n",
    "    terms = entry['terms']\n",
    "    \n",
    "    tokens, ner_tags = create_ner_tags(text, terms, tokenizer, label2id)\n",
    "    entry['tokens'] = tokens\n",
    "    entry['ner_tags'] = ner_tags\n",
    "    \n",
    "    if i % 200 == 0:\n",
    "        print(f\"  Processed {i}/{len(dev_sentences)}\")\n",
    "\n",
    "print(f\"✓ Dev data processed: {len(dev_sentences)} sentences\")\n",
    "\n",
    "print(f\"\\nSample train sentence:\")\n",
    "print(f\"  Text: {train_sentences[6]['sentence_text']}\")\n",
    "print(f\"  Terms: {train_sentences[6]['terms']}\")\n",
    "token_tags = []\n",
    "for token, tag in zip(train_sentences[6]['tokens'], train_sentences[6]['ner_tags']):\n",
    "    token_tags.append((token, id2label[tag]))\n",
    "print(f\"\\n{pd.DataFrame(token_tags, columns=['Token', 'Tag']).to_markdown()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f0740c",
   "metadata": {},
   "source": [
    "## Prepare Dataset for BERT Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "98289860",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T10:53:14.408009Z",
     "start_time": "2025-11-11T10:53:14.377560Z"
    }
   },
   "outputs": [],
   "source": [
    "class TokenClassificationDataset(Dataset):\n",
    "    \"\"\"Dataset per token classification usando i token BERT e le ner_tags già pre-calcolate.\"\"\"\n",
    "    \n",
    "    def __init__(self, sentences, tokenizer, max_length=512):\n",
    "        \"\"\"\n",
    "        sentences: lista di dict (train_sentences / dev_sentences),\n",
    "                   ognuno con 'sentence_text', 'tokens', 'ner_tags'\n",
    "        \"\"\"\n",
    "        self.sentences = sentences\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.sentences[idx]\n",
    "        \n",
    "        # subtoken BERT (senza special tokens) e label allineate 1:1\n",
    "        bert_tokens = entry[\"tokens\"]\n",
    "        bert_labels = entry[\"ner_tags\"]  # lista di int (id delle label)\n",
    "\n",
    "        # converti i token in ids\n",
    "        subtoken_ids = self.tokenizer.convert_tokens_to_ids(bert_tokens)\n",
    "\n",
    "        # rispetta il max_length: lasciamo spazio per CLS e SEP\n",
    "        max_subtokens = self.max_length - 2\n",
    "        subtoken_ids = subtoken_ids[:max_subtokens]\n",
    "        bert_labels = bert_labels[:max_subtokens]\n",
    "\n",
    "        # costruisci input_ids con CLS e SEP\n",
    "        input_ids = [self.tokenizer.cls_token_id] + subtoken_ids + [self.tokenizer.sep_token_id]\n",
    "\n",
    "        # mask: 1 per token reali (CLS + subtokens + SEP)\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "\n",
    "        # labels: -100 per CLS/SEP, poi le nostre label\n",
    "        labels = [-100] + bert_labels + [-100]\n",
    "\n",
    "        assert len(input_ids) == len(attention_mask) == len(labels)\n",
    "\n",
    "        # NON facciamo padding qui: ci pensa DataCollatorForTokenClassification\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(input_ids, dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(attention_mask, dtype=torch.long),\n",
    "            \"labels\": torch.tensor(labels, dtype=torch.long),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d622d3be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T10:53:15.058372Z",
     "start_time": "2025-11-11T10:53:14.442557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training datasets...\n",
      "✓ Training dataset: 2308 examples\n",
      "✓ Dev dataset: 577 examples\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating training datasets...\")\n",
    "\n",
    "train_dataset = TokenClassificationDataset(\n",
    "    sentences=train_sentences,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=512\n",
    ")\n",
    "\n",
    "dev_dataset = TokenClassificationDataset(\n",
    "    sentences=dev_sentences,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=512,\n",
    ")\n",
    "\n",
    "print(f\"✓ Training dataset: {len(train_dataset)} examples\")\n",
    "print(f\"✓ Dev dataset: {len(dev_dataset)} examples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75ca5f8",
   "metadata": {},
   "source": [
    "## Configure Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ebe321ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data collator initialized\n"
     ]
    }
   ],
   "source": [
    "# Setup data collator for token classification\n",
    "# Data collator is used to dynamically pad inputs and labels\n",
    "data_collator = DataCollatorForTokenClassification(\n",
    "    tokenizer=tokenizer,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "print(\"✓ Data collator initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "52f622a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "def align_predictions(predictions, label_ids):\n",
    "    preds = np.argmax(predictions, axis=2)\n",
    "    batch_true = []\n",
    "    batch_pred = []\n",
    "\n",
    "    for pred, lab in zip(preds, label_ids):\n",
    "        true_labels = []\n",
    "        pred_labels = []\n",
    "        for p, l in zip(pred, lab):\n",
    "            if l == -100:\n",
    "                continue\n",
    "            true_labels.append(id2label[l])\n",
    "            pred_labels.append(id2label[p])\n",
    "        batch_true.append(true_labels)\n",
    "        batch_pred.append(pred_labels)\n",
    "\n",
    "    return batch_pred, batch_true\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    y_pred, y_true = align_predictions(logits, labels)\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision_score(y_true, y_pred),\n",
    "        \"recall\":    recall_score(y_true, y_pred),\n",
    "        \"f1\":        f1_score(y_true, y_pred),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b250c850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Training configuration ready\n",
      "  Batch size: 16\n",
      "  Epochs: 7\n",
      "  Learning rate: 2e-05\n"
     ]
    }
   ],
   "source": [
    "# Define training arguments\n",
    "\"\"\" training_args = TrainingArguments(\n",
    "    output_dir=output_model_dir,\n",
    "    learning_rate= 3e-5,    # before 2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=7,\n",
    "    weight_decay=0.01, #\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False, #push the model to hugging face\n",
    "    logging_steps=100,\n",
    "    save_total_limit=2,\n",
    "    seed=42,\n",
    "    fp16=torch.cuda.is_available(), #only if you have gpu\n",
    "    report_to=\"none\"\n",
    ") \"\"\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_model_dir,\n",
    "    learning_rate=3e-5,                  # TORNA a 2e-5 (2e-5_changed) - PRIMA 3e-5\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=7,                  # tetto massimo\n",
    "    weight_decay=0.01,\n",
    "\n",
    "    # !!! PARAMETRO CORRETTO !!!\n",
    "    eval_strategy=\"epoch\",         # non eval_strategy\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "\n",
    "    # scheduler + warmup\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    warmup_ratio=0.1,\n",
    "\n",
    "    logging_steps=100,\n",
    "    save_total_limit=2,\n",
    "    seed=42,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    report_to=\"none\",\n",
    "\n",
    "    # best model basato sulla F1 (se compute_metrics la espone)\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    ")\n",
    "\n",
    "print(\"✓ Training configuration ready\")\n",
    "print(f\"  Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"  Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"  Learning rate: {training_args.learning_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b55df57",
   "metadata": {},
   "source": [
    "## Train BERT Model\n",
    "\n",
    "Note: This cell might take several minutes to run.\n",
    "\n",
    "\n",
    "**Additional configurations to test**\n",
    "- Aggregate training samples per paragraph/document\n",
    "- Change hyperparameters (*learning_rate*, *batch_size*, *num_train_epochs*, *weight_decay*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b6c44051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Trainer...\n",
      "✓ Trainer initialized\n",
      "  Training samples: 2308\n",
      "  Evaluation samples: 577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_34096\\636005938.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "# Initialize Trainer\n",
    "print(\"Initializing Trainer...\")\n",
    "\"\"\" trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=dev_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ") \"\"\"\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=dev_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,                 # con F1 token-level\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    ")\n",
    "print(\"✓ Trainer initialized\")\n",
    "print(f\"  Training samples: {len(train_dataset)}\")\n",
    "print(f\"  Evaluation samples: {len(dev_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "900dd7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Starting model training...\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1015' max='1015' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1015/1015 1:02:02, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.524200</td>\n",
       "      <td>0.166736</td>\n",
       "      <td>0.445783</td>\n",
       "      <td>0.585973</td>\n",
       "      <td>0.506354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.166100</td>\n",
       "      <td>0.132566</td>\n",
       "      <td>0.681395</td>\n",
       "      <td>0.662896</td>\n",
       "      <td>0.672018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>0.126107</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.760181</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.064400</td>\n",
       "      <td>0.128943</td>\n",
       "      <td>0.648000</td>\n",
       "      <td>0.733032</td>\n",
       "      <td>0.687898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.134354</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.746606</td>\n",
       "      <td>0.721311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.137543</td>\n",
       "      <td>0.700210</td>\n",
       "      <td>0.755656</td>\n",
       "      <td>0.726877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>0.140826</td>\n",
       "      <td>0.703158</td>\n",
       "      <td>0.755656</td>\n",
       "      <td>0.728462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\super\\Documents\\UniPd\\ATA\\ATE-IT_SofiaMaule\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\super\\Documents\\UniPd\\ATA\\ATE-IT_SofiaMaule\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\super\\Documents\\UniPd\\ATA\\ATE-IT_SofiaMaule\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\super\\Documents\\UniPd\\ATA\\ATE-IT_SofiaMaule\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\super\\Documents\\UniPd\\ATA\\ATE-IT_SofiaMaule\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\super\\Documents\\UniPd\\ATA\\ATE-IT_SofiaMaule\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "✓ TRAINING COMPLETED!\n",
      "============================================================\n",
      "Training time: 62.09 minutes\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "print(\"=\"*60)\n",
    "print(\"Starting model training...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import time\n",
    "training_start_time = time.time()\n",
    "\n",
    "train_result = trainer.train()\n",
    "#trainer.train(resume_from_checkpoint=\"models/bert_token_classification/checkpoint-725\")\n",
    "\n",
    "\n",
    "training_duration = time.time() - training_start_time\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ TRAINING COMPLETED!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training time: {training_duration/60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9d8a7e",
   "metadata": {},
   "source": [
    "## Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4be37024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving trained model...\n",
      "✓ Model saved to: models/bert_token_classification_2e-5_changed\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "print(\"Saving trained model...\")\n",
    "\n",
    "os.makedirs(output_model_dir, exist_ok=True)\n",
    "trainer.save_model(output_model_dir)\n",
    "tokenizer.save_pretrained(output_model_dir)\n",
    "\n",
    "print(f\"✓ Model saved to: {output_model_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca318c0",
   "metadata": {},
   "source": [
    "## Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bfb4cef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model for inference...\n",
      "✓ Model loaded from: models/bert_token_classification_2e-5_changed\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model for inference\n",
    "print(\"Loading trained model for inference...\")\n",
    "\n",
    "inference_model = AutoModelForTokenClassification.from_pretrained(output_model_dir)\n",
    "inference_tokenizer = AutoTokenizer.from_pretrained(output_model_dir)\n",
    "inference_model.eval()\n",
    "\n",
    "print(f\"✓ Model loaded from: {output_model_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b2a2d4",
   "metadata": {},
   "source": [
    "## Predict on Dev Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8ef207fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_term(term: str) -> str:\n",
    "    t = term.strip()\n",
    "    # normalizza spazi\n",
    "    t = \" \".join(t.split())\n",
    "    # togli punteggiatura solo ai bordi (non in mezzo)\n",
    "    t = t.strip(string.punctuation + \"«»“”'\\\"\")\n",
    "    return t.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a8116d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(31102, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "inference_model = AutoModelForTokenClassification.from_pretrained(output_model_dir).to(device)\n",
    "id2label = inference_model.config.id2label  # override quella globale, se vuoi\n",
    "inference_tokenizer = AutoTokenizer.from_pretrained(output_model_dir)\n",
    "inference_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2699ea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_inference(model, tokenizer, text, id2label):\n",
    "    encoded = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        return_offsets_mapping=True,\n",
    "        max_length=512,\n",
    "    )\n",
    "    offset_mapping = encoded[\"offset_mapping\"][0]  # (seq_len, 2)\n",
    "    attention_mask = encoded[\"attention_mask\"][0]\n",
    "\n",
    "    inputs = {k: v.to(device) for k, v in encoded.items() if k != \"offset_mapping\"}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predicted_labels = outputs.logits.argmax(dim=-1)[0].cpu()\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(encoded[\"input_ids\"][0])\n",
    "    labels = [id2label[p.item()] for p in predicted_labels]\n",
    "\n",
    "    predicted_terms = []\n",
    "    current_term_chars = []\n",
    "\n",
    "    text_proc = text  # già preprocessato prima di chiamare la funzione\n",
    "\n",
    "    for (token, label, mask, (start, end)) in zip(tokens, labels, attention_mask, offset_mapping):\n",
    "        if mask.item() == 0:\n",
    "            continue  # padding\n",
    "\n",
    "        # salta special token (meglio che per stringa)\n",
    "        if start == 0 and end == 0:\n",
    "            continue\n",
    "\n",
    "        if label == \"B-TERM\":\n",
    "            if current_term_chars:\n",
    "                predicted_terms.append(\"\".join(current_term_chars))\n",
    "                current_term_chars = []\n",
    "            current_term_chars.append(text_proc[start:end])\n",
    "        elif label == \"I-TERM\" and current_term_chars:\n",
    "            current_term_chars.append(\" \" + text_proc[start:end])\n",
    "        else:\n",
    "            if current_term_chars:\n",
    "                predicted_terms.append(\"\".join(current_term_chars))\n",
    "                current_term_chars = []\n",
    "\n",
    "    if current_term_chars:\n",
    "        predicted_terms.append(\"\".join(current_term_chars))\n",
    "\n",
    "    predicted_terms = [clean_term(t) for t in predicted_terms if clean_term(t)]\n",
    "    return predicted_terms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e6a9127b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference on dev set...\n",
      "  Processing 0/577\n",
      "  Processing 200/577\n",
      "  Processing 400/577\n",
      "✓ Inference completed: 577 predictions\n"
     ]
    }
   ],
   "source": [
    "# Run inference on all dev sentences\n",
    "print(\"Running inference on dev set...\")\n",
    "bert_preds = []\n",
    "\n",
    "for i, sentence in enumerate(dev_sentences):\n",
    "    if i % 200 == 0:\n",
    "        print(f\"  Processing {i}/{len(dev_sentences)}\")\n",
    "    \n",
    "    predicted_terms = perform_inference(\n",
    "        inference_model,\n",
    "        inference_tokenizer,\n",
    "        preprocess_text(sentence[\"sentence_text\"]), #CHANGED\n",
    "        id2label\n",
    "    )\n",
    "    bert_preds.append(predicted_terms)\n",
    "\n",
    "print(f\"✓ Inference completed: {len(bert_preds)} predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "34636c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.14082567393779755, 'eval_precision': 0.7031578947368421, 'eval_recall': 0.755656108597285, 'eval_f1': 0.7284623773173392, 'eval_runtime': 20.9162, 'eval_samples_per_second': 27.586, 'eval_steps_per_second': 1.769, 'epoch': 7.0}\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate()\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "99bf21fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TERM-LEVEL METRICS (DIRECT FROM bert_preds) ===\n",
      "Precision: 0.460\n",
      "Recall:    0.446\n",
      "F1:        0.453\n",
      "TP=201, FP=236, FN=250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4599542333990857, 0.44567627493468565, 0.45270269769374955)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_for_eval(t: str) -> str:\n",
    "    # stessa logica di clean_term / preprocess_text\n",
    "    t = t.strip().lower()\n",
    "    t = \" \".join(t.split())\n",
    "    # togli punteggiatura ai bordi\n",
    "    t = t.strip(string.punctuation + \"«»“”'\\\"\")\n",
    "    return t\n",
    "\n",
    "def compute_term_level_metrics_from_bert(dev_sentences, bert_preds):\n",
    "    \"\"\"\n",
    "    dev_sentences: lista di dict (già pre-processati) con campo 'terms'\n",
    "    bert_preds:    lista parallela di liste di termini predetti\n",
    "    \"\"\"\n",
    "    assert len(dev_sentences) == len(bert_preds)\n",
    "\n",
    "    tp = fp = fn = 0\n",
    "\n",
    "    for entry, pred_terms in zip(dev_sentences, bert_preds):\n",
    "        gold_terms = [normalize_for_eval(t) for t in entry[\"terms\"]]\n",
    "        pred_terms = [normalize_for_eval(t) for t in pred_terms]\n",
    "\n",
    "        gold_set = set(gold_terms)\n",
    "        pred_set = set(pred_terms)\n",
    "\n",
    "        tp += len(gold_set & pred_set)\n",
    "        fp += len(pred_set - gold_set)\n",
    "        fn += len(gold_set - pred_set)\n",
    "\n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall    = tp / (tp + fn + 1e-8)\n",
    "    f1        = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "\n",
    "    print(\"=== TERM-LEVEL METRICS (DIRECT FROM bert_preds) ===\")\n",
    "    print(f\"Precision: {precision:.3f}\")\n",
    "    print(f\"Recall:    {recall:.3f}\")\n",
    "    print(f\"F1:        {f1:.3f}\")\n",
    "    print(f\"TP={tp}, FP={fp}, FN={fn}\")\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "compute_term_level_metrics_from_bert(dev_sentences, bert_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "067a1d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BERT TOKEN CLASSIFICATION RESULTS\n",
      "============================================================\n",
      "\n",
      "Micro-averaged Metrics:\n",
      "  Precision: 0.4600\n",
      "  Recall:    0.4457\n",
      "  F1 Score:  0.4527\n",
      "  TP=201, FP=236, FN=250\n",
      "\n",
      "Type-level Metrics:\n",
      "  Type Precision: 0.3948\n",
      "  Type Recall:    0.3802\n",
      "  Type F1 Score:  0.3874\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Prepare gold standard and predictions for evaluation\n",
    "dev_gold = [s['terms'] for s in dev_sentences]\n",
    "\n",
    "# Evaluate using competition metrics\n",
    "precision, recall, f1, tp, fp, fn= micro_f1_score(dev_gold, bert_preds)\n",
    "type_precision, type_recall, type_f1 = type_f1_score(dev_gold, bert_preds)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BERT TOKEN CLASSIFICATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nMicro-averaged Metrics:\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall:    {recall:.4f}\")\n",
    "print(f\"  F1 Score:  {f1:.4f}\")\n",
    "print(f\"  TP={tp}, FP={fp}, FN={fn}\")\n",
    "\n",
    "print(\"\\nType-level Metrics:\")\n",
    "print(f\"  Type Precision: {type_precision:.4f}\")\n",
    "print(f\"  Type Recall:    {type_recall:.4f}\")\n",
    "print(f\"  Type F1 Score:  {type_f1:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186cc3f3",
   "metadata": {},
   "source": [
    "BERT TOKEN CLASSIFICATION RESULTS (2e-5)\n",
    "\n",
    "Micro-averaged Metrics:\n",
    "Precision: 0.7079\n",
    "Recall:    0.6718\n",
    "F1 Score:  0.6894\n",
    "TP=303, FP=125, FN=148\n",
    "\n",
    "Type-level Metrics:\n",
    "Type Precision: 0.6545\n",
    "Type Recall:    0.5950\n",
    "Type F1 Score:  0.6234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "96a1c3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved 577 predictions to predictions/subtask_a_dev_bert_token_classification_preds_extended_2e-5_changed.json\n"
     ]
    }
   ],
   "source": [
    "# Save predictions in competition format\n",
    "def save_predictions(predictions, sentences, output_path):\n",
    "    \"\"\"Save predictions in competition format.\"\"\"\n",
    "    output = {'data': []}\n",
    "    for pred, sent in zip(predictions, sentences):\n",
    "        output['data'].append({\n",
    "            'document_id': sent['document_id'],\n",
    "            'paragraph_id': sent['paragraph_id'],\n",
    "            'sentence_id': sent['sentence_id'],\n",
    "            'term_list': pred\n",
    "        })\n",
    "    \n",
    "    os.makedirs(os.path.dirname(output_path) or '.', exist_ok=True)\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(output, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"✓ Saved {len(predictions)} predictions to {output_path}\")\n",
    "\n",
    "\n",
    "save_predictions(bert_preds, dev_sentences, 'predictions/subtask_a_dev_bert_token_classification_preds_extended_2e-5_changed.json') #CHANGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6f6fcc",
   "metadata": {},
   "source": [
    "## Example Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8465b3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Predictions:\n",
      "\n",
      "Sentence: il presente disciplinare per la gestione dei centri di raccolta comunali è stato redatto ai sensi e ...\n",
      "Gold terms: ['disciplina dei centri di raccolta dei rifiuti urbani raccolti in modo differenziato', 'disciplinare per la gestione dei centri di raccolta comunali']\n",
      "BERT predictions: ['disciplinare per la gestione dei centri di raccolta comunali', 'centri di raccolta dei rifiuti urbani raccolti in']\n",
      "✓ Correct: 1\n",
      "✗ Missed: 1\n",
      "✗ Wrong: 1\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: è un servizio supplementare di raccolta, rivolto a famiglie con bambini al di sotto dei 3 anni o con...\n",
      "Gold terms: ['raccolta']\n",
      "BERT predictions: ['servizio']\n",
      "✓ Correct: 0\n",
      "✗ Missed: 1\n",
      "✗ Wrong: 1\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: ll servizio di raccolta dei rifiuti derivanti da sfalci e potature è gestito dalla buttol srl con il...\n",
      "Gold terms: ['servizio di raccolta dei rifiuti', 'sfalci e potature']\n",
      "BERT predictions: ['servizio di raccolta dei rifiuti derivanti']\n",
      "✓ Correct: 0\n",
      "✗ Missed: 2\n",
      "✗ Wrong: 1\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: #differenziati...\n",
      "Gold terms: ['differenziati']\n",
      "BERT predictions: ['differenzia ti']\n",
      "✓ Correct: 0\n",
      "✗ Missed: 1\n",
      "✗ Wrong: 1\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: multimateriale; sacchetto blu trasparente; lunedì giovedì...\n",
      "Gold terms: ['multimateriale', 'sacchetto trasparente']\n",
      "BERT predictions: ['multi mate ria le']\n",
      "✓ Correct: 0\n",
      "✗ Missed: 2\n",
      "✗ Wrong: 1\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show example predictions\n",
    "print(\"Example Predictions:\\n\")\n",
    "\n",
    "count = 0\n",
    "for i in range(len(dev_sentences)):\n",
    "    if len(dev_gold[i]) > 0 and count < 5:\n",
    "        print(f\"Sentence: {dev_sentences[i]['sentence_text'][:100]}...\")\n",
    "        print(f\"Gold terms: {dev_gold[i][:5]}\")\n",
    "        print(f\"BERT predictions: {bert_preds[i][:5]}\")\n",
    "        \n",
    "        correct = set(dev_gold[i]) & set(bert_preds[i])\n",
    "        missed = set(dev_gold[i]) - set(bert_preds[i])\n",
    "        wrong = set(bert_preds[i]) - set(dev_gold[i])\n",
    "        \n",
    "        print(f\"✓ Correct: {len(correct)}\")\n",
    "        print(f\"✗ Missed: {len(missed)}\")\n",
    "        print(f\"✗ Wrong: {len(wrong)}\")\n",
    "        print(\"-\"*80)\n",
    "        print()\n",
    "        \n",
    "        count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
