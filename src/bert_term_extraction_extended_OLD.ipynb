{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "300afcee",
   "metadata": {},
   "source": [
    "# BERT Token Classification for Italian Term Extraction\n",
    "\n",
    "This notebook demonstrates a BERT-based approach to term extraction:\n",
    "- Uses BIO tagging scheme (Beginning-Inside-Outside)\n",
    "- Fine-tunes Italian BERT model for token classification\n",
    "- Trains on labeled data to recognize term boundaries\n",
    "\n",
    "Dataset: EvalITA 2025 ATE-IT (Automatic Term Extraction - Italian Testbed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257d342c",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bacd6f61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T10:43:33.424051Z",
     "start_time": "2025-11-11T10:42:33.407768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete\n",
      "PyTorch version: 2.8.0+cpu\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer, #choose this\n",
    "    AutoModelForTokenClassification,  #choose this\n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    DataCollatorForTokenClassification\n",
    ")\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Setup complete\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8767bd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['O', 'B-TERM', 'I-TERM']\n",
      "Label to ID: {'O': 0, 'B-TERM': 1, 'I-TERM': 2}\n",
      "\n",
      "Model: dbmdz/bert-base-italian-uncased\n",
      "Output directory: models/bert_token_classification_2e-5_changed\n"
     ]
    }
   ],
   "source": [
    "# Define label mappings for BIO tagging scheme\n",
    "label_list = ['O', 'B-TERM', 'I-TERM']\n",
    "label2id = {k: v for v, k in enumerate(label_list)}\n",
    "id2label = {v: k for v, k in enumerate(label_list)}\n",
    "\n",
    "print(f\"Labels: {label_list}\")\n",
    "print(f\"Label to ID: {label2id}\")\n",
    "\n",
    "# Model configuration\n",
    "model_name = \"dbmdz/bert-base-italian-uncased\" #chosen in hugging face -->  bert-base-italian-cased-wwm\n",
    "#output_model_dir = \"models/bert_token_classification\"\n",
    "#output_model_dir = \"models/bert_token_classification_3e-5\"\n",
    "output_model_dir = \"models/bert_token_classification_2e-5_changed\"\n",
    "print(f\"\\nModel: {model_name}\")\n",
    "print(f\"Output directory: {output_model_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8142a69c",
   "metadata": {},
   "source": [
    "## Data Loading and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfe3bbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "def load_jsonl(path: str):\n",
    "    \"\"\"Load a JSON lines file or JSON array file.\"\"\"\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read().strip()\n",
    "    if not text:\n",
    "        return []\n",
    "    try:\n",
    "        data = json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        data = []\n",
    "        for line in text.splitlines():\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "#aggregate the terms concatenating the paragraphs\n",
    "def build_sentence_gold_map(records):\n",
    "    \"\"\"Convert dataset rows into list of sentences with aggregated terms.\"\"\"\n",
    "    out = {}\n",
    "    \n",
    "    if isinstance(records, dict) and 'data' in records:\n",
    "        rows = records['data']\n",
    "    else:\n",
    "        rows = records\n",
    "    \n",
    "    for r in rows:\n",
    "        key = (r.get('document_id'), r.get('paragraph_id'), r.get('sentence_id'))\n",
    "        if key not in out:\n",
    "            out[key] = {\n",
    "                'document_id': r.get('document_id'),\n",
    "                'paragraph_id': r.get('paragraph_id'),\n",
    "                'sentence_id': r.get('sentence_id'),\n",
    "                'sentence_text': r.get('sentence_text', ''),\n",
    "                'terms': []\n",
    "            }\n",
    "        \n",
    "        if isinstance(r.get('term_list'), list):\n",
    "            for t in r.get('term_list'):\n",
    "                if t and t not in out[key]['terms']:\n",
    "                    out[key]['terms'].append(t)\n",
    "        else:\n",
    "            term = r.get('term')\n",
    "            if term and term not in out[key]['terms']:\n",
    "                out[key]['terms'].append(term)\n",
    "    \n",
    "    return list(out.values())\n",
    "\n",
    "\n",
    "print(\"✓ Data loading functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05486208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sentences: 2308\n",
      "Dev sentences: 577\n",
      "\n",
      "Example sentence:\n",
      "  Text: AFFIDAMENTO DEL “SERVIZIO DI SPAZZAMENTO, RACCOLTA, TRASPORTO E SMALTIMENTO/RECUPERO DEI RIFIUTI URBANI ED ASSIMILATI E SERVIZI COMPLEMENTARI DELLA CITTA' DI AGROPOLI” VALEVOLE PER UN QUINQUENNIO\n",
      "  Terms: ['raccolta', 'recupero', 'servizio di raccolta', 'servizio di spazzamento', 'smaltimento', 'trasporto']\n"
     ]
    }
   ],
   "source": [
    "# Load training and dev data\n",
    "train_data = load_jsonl('../data/subtask_a_train.json')\n",
    "dev_data = load_jsonl('../data/subtask_a_dev.json')\n",
    "\n",
    "train_sentences = build_sentence_gold_map(train_data)\n",
    "dev_sentences = build_sentence_gold_map(dev_data)\n",
    "\n",
    "print(f\"Training sentences: {len(train_sentences)}\")\n",
    "print(f\"Dev sentences: {len(dev_sentences)}\")\n",
    "print(f\"\\nExample sentence:\")\n",
    "print(f\"  Text: {train_sentences[6]['sentence_text']}\")\n",
    "print(f\"  Terms: {train_sentences[6]['terms']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f56f629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, force_lower=True):\n",
    "    # fix encoding issues\n",
    "    text = text.replace(\"\\u00a0\", \" \")\n",
    "\n",
    "    # normalize spaces\n",
    "    text = \" \".join(text.split())\n",
    "\n",
    "    # unify apostrophes\n",
    "    text = text.replace(\"’\", \"'\").replace(\"`\", \"'\")\n",
    "\n",
    "    # lowercase if model is uncased\n",
    "    if force_lower:\n",
    "        text = text.lower()\n",
    "\n",
    "    # remove weird control characters\n",
    "    text = \"\".join(c for c in text if c.isprintable())\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9e0c703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sentences: 2308\n",
      "Dev sentences: 577\n",
      "\n",
      "Example sentence:\n",
      "  Text: affidamento del “servizio di spazzamento, raccolta, trasporto e smaltimento/recupero dei rifiuti urbani ed assimilati e servizi complementari della citta' di agropoli” valevole per un quinquennio\n",
      "  Terms: ['raccolta', 'recupero', 'servizio di raccolta', 'servizio di spazzamento', 'smaltimento', 'trasporto']\n"
     ]
    }
   ],
   "source": [
    "for entry in train_sentences:\n",
    "    # pulisci il testo della frase\n",
    "    entry[\"sentence_text\"] = preprocess_text(entry[\"sentence_text\"])\n",
    "    # (opzionale ma consigliato) pulisci anche i termini gold\n",
    "    entry[\"terms\"] = [preprocess_text(t) for t in entry[\"terms\"]]\n",
    "\n",
    "for entry in dev_sentences:\n",
    "    entry[\"sentence_text\"] = preprocess_text(entry[\"sentence_text\"])\n",
    "    entry[\"terms\"] = [preprocess_text(t) for t in entry[\"terms\"]]\n",
    "\n",
    "print(f\"Training sentences: {len(train_sentences)}\")\n",
    "print(f\"Dev sentences: {len(dev_sentences)}\")\n",
    "print(f\"\\nExample sentence:\")\n",
    "print(f\"  Text: {train_sentences[6]['sentence_text']}\")\n",
    "print(f\"  Terms: {train_sentences[6]['terms']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90654f36",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "Using the official evaluation metrics from the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2708c291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Evaluation functions defined\n"
     ]
    }
   ],
   "source": [
    "def micro_f1_score(gold_standard, system_output):\n",
    "    \"\"\"\n",
    "    Evaluates performance using Precision, Recall, and F1 score \n",
    "    based on individual term matching (micro-average).\n",
    "    \"\"\"\n",
    "    total_true_positives = 0\n",
    "    total_false_positives = 0\n",
    "    total_false_negatives = 0\n",
    "    \n",
    "    for gold, system in zip(gold_standard, system_output):\n",
    "        gold_set = set(gold)\n",
    "        system_set = set(system)\n",
    "        \n",
    "        true_positives = len(gold_set.intersection(system_set))\n",
    "        false_positives = len(system_set - gold_set)\n",
    "        false_negatives = len(gold_set - system_set)\n",
    "        \n",
    "        total_true_positives += true_positives\n",
    "        total_false_positives += false_positives\n",
    "        total_false_negatives += false_negatives\n",
    "    \n",
    "    precision = total_true_positives / (total_true_positives + total_false_positives) if (total_true_positives + total_false_positives) > 0 else 0\n",
    "    recall = total_true_positives / (total_true_positives + total_false_negatives) if (total_true_positives + total_false_negatives) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1, total_true_positives, total_false_positives, total_false_negatives\n",
    "\n",
    "\n",
    "def type_f1_score(gold_standard, system_output):\n",
    "    \"\"\"\n",
    "    Evaluates performance using Type Precision, Type Recall, and Type F1 score\n",
    "    based on the set of unique terms extracted at least once across the entire dataset.\n",
    "    \"\"\"\n",
    "    all_gold_terms = set()\n",
    "    for item_terms in gold_standard:\n",
    "        all_gold_terms.update(item_terms)\n",
    "    \n",
    "    all_system_terms = set()\n",
    "    for item_terms in system_output:\n",
    "        all_system_terms.update(item_terms)\n",
    "    \n",
    "    type_true_positives = len(all_gold_terms.intersection(all_system_terms))\n",
    "    type_false_positives = len(all_system_terms - all_gold_terms)\n",
    "    type_false_negatives = len(all_gold_terms - all_system_terms)\n",
    "    \n",
    "    type_precision = type_true_positives / (type_true_positives + type_false_positives) if (type_true_positives + type_false_positives) > 0 else 0\n",
    "    type_recall = type_true_positives / (type_true_positives + type_false_negatives) if (type_true_positives + type_false_negatives) > 0 else 0\n",
    "    type_f1 = 2 * (type_precision * type_recall) / (type_precision + type_recall) if (type_precision + type_recall) > 0 else 0\n",
    "    \n",
    "    return type_precision, type_recall, type_f1\n",
    "\n",
    "\n",
    "print(\"✓ Evaluation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfac0bc",
   "metadata": {},
   "source": [
    "## Initialize BERT Model and Tokenizer\n",
    "\n",
    "Always load\n",
    "- tokenizer\n",
    "- bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bb1b27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing BERT tokenizer and model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-italian-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Tokenizer loaded: BertTokenizerFast\n",
      "✓ Model loaded with 3 labels\n",
      "  Vocabulary size: 31102\n"
     ]
    }
   ],
   "source": [
    "# Initialize tokenizer and model\n",
    "print(\"Initializing BERT tokenizer and model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name, \n",
    "    num_labels=len(label_list), #labels we're trying to predict\n",
    "    id2label=id2label, \n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "print(f\"✓ Tokenizer loaded: {tokenizer.__class__.__name__}\")\n",
    "print(f\"✓ Model loaded with {model.num_labels} labels\")\n",
    "print(f\"  Vocabulary size: {tokenizer.vocab_size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681cd148",
   "metadata": {},
   "source": [
    "## BIO Tag Generation for Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "158f6ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing BERT tokenizer and model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-italian-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Tokenizer loaded: BertTokenizerFast\n",
      "✓ Model loaded with 3 labels\n",
      "  Vocabulary size: 31102\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "# Initialize tokenizer and model\n",
    "print(\"Initializing BERT tokenizer and model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name, \n",
    "    num_labels=len(label_list), #labels we're trying to predict\n",
    "    id2label=id2label, \n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "print(f\"✓ Tokenizer loaded: {tokenizer.__class__.__name__}\")\n",
    "print(f\"✓ Model loaded with {model.num_labels} labels\")\n",
    "print(f\"  Vocabulary size: {tokenizer.vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0668cf5c",
   "metadata": {},
   "source": [
    "## Process Training and Dev Data with BIO Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e58f892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ner_tags(text: str, terms: list[str], tokenizer, label2id: dict):\n",
    "    \"\"\"\n",
    "    Crea token e BIO tag per una frase, dato l'elenco dei termini gold.\n",
    "\n",
    "    text: frase pre-processata (come in preprocess_text)\n",
    "    terms: lista di termini gold pre-processati\n",
    "    tokenizer: tokenizer HuggingFace\n",
    "    label2id: dict, es. {'O': 0, 'B-TERM': 1, 'I-TERM': 2}\n",
    "\n",
    "    Ritorna:\n",
    "        tokens: list[str]\n",
    "        ner_tags: list[int] (stessa lunghezza di tokens)\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 1) Trova tutti gli span (start_char, end_char) dei termini nel testo ---\n",
    "\n",
    "    def is_boundary(ch: str | None) -> bool:\n",
    "        \"\"\"True se il carattere è None o non alfanumerico (quindi buon confine di parola).\"\"\"\n",
    "        if ch is None:\n",
    "            return True\n",
    "        return not ch.isalnum()\n",
    "\n",
    "    spans = []  # lista di (start, end)\n",
    "    for term in terms:\n",
    "        term = term.strip()\n",
    "        if not term:\n",
    "            continue\n",
    "\n",
    "        start = 0\n",
    "        while True:\n",
    "            idx = text.find(term, start)\n",
    "            if idx == -1:\n",
    "                break\n",
    "\n",
    "            end = idx + len(term)\n",
    "\n",
    "            # Controllo confini di parola\n",
    "            before = text[idx - 1] if idx > 0 else None\n",
    "            after = text[end] if end < len(text) else None\n",
    "\n",
    "            if is_boundary(before) and is_boundary(after):\n",
    "                spans.append((idx, end))\n",
    "\n",
    "            start = idx + len(term)\n",
    "\n",
    "    # opzionale: ordina gli span per inizio\n",
    "    spans.sort(key=lambda x: x[0])\n",
    "\n",
    "    # --- 2) Tokenizza con offset mapping ---\n",
    "    encoded = tokenizer(\n",
    "        text,\n",
    "        return_offsets_mapping=True,\n",
    "        add_special_tokens=False\n",
    "    )\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(encoded[\"input_ids\"])\n",
    "    offsets = encoded[\"offset_mapping\"]\n",
    "\n",
    "    ner_tags = [label2id[\"O\"]] * len(tokens)\n",
    "\n",
    "    # --- 3) Assegna BIO tag in base agli span ---\n",
    "    for i, (tok_start, tok_end) in enumerate(offsets):\n",
    "        # alcuni tokenizer possono dare (0, 0) per token speciali, ma noi add_special_tokens=False\n",
    "        if tok_start == tok_end:\n",
    "            ner_tags[i] = label2id[\"O\"]\n",
    "            continue\n",
    "\n",
    "        tag = \"O\"\n",
    "        for span_start, span_end in spans:\n",
    "            # se il token inizia dentro uno span\n",
    "            if tok_start >= span_start and tok_start < span_end:\n",
    "                if tok_start == span_start:\n",
    "                    tag = \"B-TERM\"\n",
    "                else:\n",
    "                    tag = \"I-TERM\"\n",
    "                break\n",
    "\n",
    "        ner_tags[i] = label2id[tag]\n",
    "\n",
    "    return tokens, ner_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a06c26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training data...\n",
      "  Processed 0/2308\n",
      "  Processed 1000/2308\n",
      "  Processed 2000/2308\n",
      "✓ Training data processed: 2308 sentences\n",
      "\n",
      "Processing dev data...\n",
      "  Processed 0/577\n",
      "  Processed 200/577\n",
      "  Processed 400/577\n",
      "✓ Dev data processed: 577 sentences\n",
      "\n",
      "Sample train sentence:\n",
      "  Text: affidamento del “servizio di spazzamento, raccolta, trasporto e smaltimento/recupero dei rifiuti urbani ed assimilati e servizi complementari della citta' di agropoli” valevole per un quinquennio\n",
      "  Terms: ['raccolta', 'recupero', 'servizio di raccolta', 'servizio di spazzamento', 'smaltimento', 'trasporto']\n",
      "\n",
      "|    | Token         | Tag    |\n",
      "|---:|:--------------|:-------|\n",
      "|  0 | affidamento   | O      |\n",
      "|  1 | del           | O      |\n",
      "|  2 | “             | O      |\n",
      "|  3 | servizio      | B-TERM |\n",
      "|  4 | di            | I-TERM |\n",
      "|  5 | spa           | I-TERM |\n",
      "|  6 | ##zzamento    | I-TERM |\n",
      "|  7 | ,             | O      |\n",
      "|  8 | raccolta      | B-TERM |\n",
      "|  9 | ,             | O      |\n",
      "| 10 | trasporto     | B-TERM |\n",
      "| 11 | e             | O      |\n",
      "| 12 | smaltimento   | B-TERM |\n",
      "| 13 | /             | O      |\n",
      "| 14 | recupero      | B-TERM |\n",
      "| 15 | dei           | O      |\n",
      "| 16 | rifiuti       | O      |\n",
      "| 17 | urbani        | O      |\n",
      "| 18 | ed            | O      |\n",
      "| 19 | assimi        | O      |\n",
      "| 20 | ##lati        | O      |\n",
      "| 21 | e             | O      |\n",
      "| 22 | servizi       | O      |\n",
      "| 23 | complementari | O      |\n",
      "| 24 | della         | O      |\n",
      "| 25 | citta         | O      |\n",
      "| 26 | '             | O      |\n",
      "| 27 | di            | O      |\n",
      "| 28 | agro          | O      |\n",
      "| 29 | ##poli        | O      |\n",
      "| 30 | ”             | O      |\n",
      "| 31 | vale          | O      |\n",
      "| 32 | ##vole        | O      |\n",
      "| 33 | per           | O      |\n",
      "| 34 | un            | O      |\n",
      "| 35 | quinqu        | O      |\n",
      "| 36 | ##ennio       | O      |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "# Process training data\n",
    "print(\"Processing training data...\")\n",
    "for i, entry in enumerate(train_sentences):\n",
    "    text = entry['sentence_text']\n",
    "    terms = entry['terms']\n",
    "    \n",
    "    tokens, ner_tags = create_ner_tags(text, terms, tokenizer, label2id)\n",
    "    entry['tokens'] = tokens\n",
    "    entry['ner_tags'] = ner_tags\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print(f\"  Processed {i}/{len(train_sentences)}\")\n",
    "\n",
    "print(f\"✓ Training data processed: {len(train_sentences)} sentences\")\n",
    "\n",
    "# Process dev data\n",
    "print(\"\\nProcessing dev data...\")\n",
    "for i, entry in enumerate(dev_sentences):\n",
    "    text = entry['sentence_text']\n",
    "    terms = entry['terms']\n",
    "    \n",
    "    tokens, ner_tags = create_ner_tags(text, terms, tokenizer, label2id)\n",
    "    entry['tokens'] = tokens\n",
    "    entry['ner_tags'] = ner_tags\n",
    "    \n",
    "    if i % 200 == 0:\n",
    "        print(f\"  Processed {i}/{len(dev_sentences)}\")\n",
    "\n",
    "print(f\"✓ Dev data processed: {len(dev_sentences)} sentences\")\n",
    "\n",
    "print(f\"\\nSample train sentence:\")\n",
    "print(f\"  Text: {train_sentences[6]['sentence_text']}\")\n",
    "print(f\"  Terms: {train_sentences[6]['terms']}\")\n",
    "token_tags = []\n",
    "for token, tag in zip(train_sentences[6]['tokens'], train_sentences[6]['ner_tags']):\n",
    "    token_tags.append((token, id2label[tag]))\n",
    "print(f\"\\n{pd.DataFrame(token_tags, columns=['Token', 'Tag']).to_markdown()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f0740c",
   "metadata": {},
   "source": [
    "## Prepare Dataset for BERT Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b30ca369",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenClassificationDataset(Dataset):\n",
    "    \"\"\"Dataset per token classification usando i token BERT e le ner_tags già pre-calcolate.\"\"\"\n",
    "    \n",
    "    def __init__(self, sentences, tokenizer, max_length=512):\n",
    "        \"\"\"\n",
    "        sentences: lista di dict (train_sentences / dev_sentences),\n",
    "                   ognuno con 'sentence_text', 'tokens', 'ner_tags'\n",
    "        \"\"\"\n",
    "        self.sentences = sentences\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.sentences[idx]\n",
    "        \n",
    "        # subtoken BERT (senza special tokens) e label allineate 1:1\n",
    "        bert_tokens = entry[\"tokens\"]\n",
    "        bert_labels = entry[\"ner_tags\"]  # lista di int (id delle label)\n",
    "\n",
    "        # converti i token in ids\n",
    "        subtoken_ids = self.tokenizer.convert_tokens_to_ids(bert_tokens)\n",
    "\n",
    "        # rispetta il max_length: lasciamo spazio per CLS e SEP\n",
    "        max_subtokens = self.max_length - 2\n",
    "        subtoken_ids = subtoken_ids[:max_subtokens]\n",
    "        bert_labels = bert_labels[:max_subtokens]\n",
    "\n",
    "        # costruisci input_ids con CLS e SEP\n",
    "        input_ids = [self.tokenizer.cls_token_id] + subtoken_ids + [self.tokenizer.sep_token_id]\n",
    "\n",
    "        # mask: 1 per token reali (CLS + subtokens + SEP)\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "\n",
    "        # labels: -100 per CLS/SEP, poi le nostre label\n",
    "        labels = [-100] + bert_labels + [-100]\n",
    "\n",
    "        assert len(input_ids) == len(attention_mask) == len(labels)\n",
    "\n",
    "        # NON facciamo padding qui: ci pensa DataCollatorForTokenClassification\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(input_ids, dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(attention_mask, dtype=torch.long),\n",
    "            \"labels\": torch.tensor(labels, dtype=torch.long),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d622d3be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T10:53:15.058372Z",
     "start_time": "2025-11-11T10:53:14.442557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training datasets...\n",
      "✓ Training dataset: 2308 examples\n",
      "✓ Dev dataset: 577 examples\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating training datasets...\")\n",
    "\n",
    "train_dataset = TokenClassificationDataset(\n",
    "    sentences=train_sentences,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=512,\n",
    ")\n",
    "\n",
    "dev_dataset = TokenClassificationDataset(\n",
    "    sentences=dev_sentences,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=512,\n",
    ")\n",
    "\n",
    "print(f\"✓ Training dataset: {len(train_dataset)} examples\")\n",
    "print(f\"✓ Dev dataset: {len(dev_dataset)} examples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75ca5f8",
   "metadata": {},
   "source": [
    "## Configure Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebe321ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data collator initialized\n"
     ]
    }
   ],
   "source": [
    "# Setup data collator for token classification\n",
    "# Data collator is used to dynamically pad inputs and labels\n",
    "data_collator = DataCollatorForTokenClassification(\n",
    "    tokenizer=tokenizer,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "print(\"✓ Data collator initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b250c850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Training configuration ready\n",
      "  Batch size: 16\n",
      "  Epochs: 5\n",
      "  Learning rate: 2e-05\n"
     ]
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_model_dir,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01, #\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False, #push the model to hugging face\n",
    "    logging_steps=100,\n",
    "    save_total_limit=2,\n",
    "    seed=42,\n",
    "    fp16=torch.cuda.is_available(), #only if you have gpu\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "print(\"✓ Training configuration ready\")\n",
    "print(f\"  Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"  Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"  Learning rate: {training_args.learning_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b55df57",
   "metadata": {},
   "source": [
    "## Train BERT Model\n",
    "\n",
    "Note: This cell might take several minutes to run.\n",
    "\n",
    "\n",
    "**Additional configurations to test**\n",
    "- Aggregate training samples per paragraph/document\n",
    "- Change hyperparameters (*learning_rate*, *batch_size*, *num_train_epochs*, *weight_decay*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c44051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Trainer...\n",
      "✓ Trainer initialized\n",
      "  Training samples: 2308\n",
      "  Evaluation samples: 577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_19472\\1594551960.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=dev_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "print(\"✓ Trainer initialized\")\n",
    "print(f\"  Training samples: {len(train_dataset)}\")\n",
    "print(f\"  Evaluation samples: {len(dev_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "900dd7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Starting model training...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\super\\Documents\\UniPd\\ATA\\ATE-IT_SofiaMaule\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='725' max='725' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [725/725 26:41, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>0.118219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.066300</td>\n",
       "      <td>0.120485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.117869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\super\\Documents\\UniPd\\ATA\\ATE-IT_SofiaMaule\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\super\\Documents\\UniPd\\ATA\\ATE-IT_SofiaMaule\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "✓ TRAINING COMPLETED!\n",
      "============================================================\n",
      "Training time: 26.77 minutes\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "print(\"=\"*60)\n",
    "print(\"Starting model training...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import time\n",
    "training_start_time = time.time()\n",
    "\n",
    "#train_result = trainer.train()\n",
    "trainer.train(resume_from_checkpoint=\"models/bert_token_classification/checkpoint-290\")\n",
    "\n",
    "\n",
    "training_duration = time.time() - training_start_time\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ TRAINING COMPLETED!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training time: {training_duration/60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9d8a7e",
   "metadata": {},
   "source": [
    "## Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4be37024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving trained model...\n",
      "✓ Model saved to: models/bert_token_classification\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "print(\"Saving trained model...\")\n",
    "\n",
    "os.makedirs(output_model_dir, exist_ok=True)\n",
    "trainer.save_model(output_model_dir)\n",
    "tokenizer.save_pretrained(output_model_dir)\n",
    "\n",
    "print(f\"✓ Model saved to: {output_model_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca318c0",
   "metadata": {},
   "source": [
    "## Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bfb4cef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model for inference...\n",
      "✓ Model loaded from: models/bert_token_classification_2e-5_changed\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model for inference\n",
    "print(\"Loading trained model for inference...\")\n",
    "\n",
    "inference_model = AutoModelForTokenClassification.from_pretrained(output_model_dir)\n",
    "inference_tokenizer = AutoTokenizer.from_pretrained(output_model_dir)\n",
    "inference_model.eval()\n",
    "\n",
    "print(f\"✓ Model loaded from: {output_model_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b2a2d4",
   "metadata": {},
   "source": [
    "## Predict on Dev Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8ef207fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_term(term: str) -> str:\n",
    "    t = term.replace(\" ##\", \"\")\n",
    "    t = \" \".join(t.split())\n",
    "    # togli punteggiatura solo ai bordi\n",
    "    t = t.strip(string.punctuation + \"«»“”'\\\"\")\n",
    "    return t.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45748c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Inference function defined\n",
      "Running inference on dev set...\n",
      "  Processing 0/577\n",
      "  Processing 200/577\n",
      "  Processing 400/577\n"
     ]
    }
   ],
   "source": [
    "def perform_inference(model, tokenizer, text, id2label):\n",
    "    \"\"\"Perform token classification inference on a single text.\"\"\"\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**{k: v for k, v in inputs.items() if k != 'offset_mapping'})\n",
    "        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        predicted_labels = torch.argmax(predictions, dim=-1)\n",
    "    \n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "    labels = [id2label[pred.item()] for pred in predicted_labels[0]]\n",
    "    \n",
    "    # Extract terms using BIO scheme\n",
    "    predicted_terms = []\n",
    "    current_term = []\n",
    "    \n",
    "    for token, label in zip(tokens, labels):\n",
    "        if token in ['[CLS]', '[SEP]', '[PAD]']:\n",
    "            continue\n",
    "            \n",
    "        if label == 'B-TERM':\n",
    "            if current_term:\n",
    "                predicted_terms.append(tokenizer.convert_tokens_to_string(current_term))\n",
    "            current_term = [token]\n",
    "        elif label == 'I-TERM' and current_term:\n",
    "            current_term.append(token)\n",
    "        else:\n",
    "            if current_term:\n",
    "                predicted_terms.append(tokenizer.convert_tokens_to_string(current_term))\n",
    "                current_term = []\n",
    "    \n",
    "    if current_term:\n",
    "        predicted_terms.append(tokenizer.convert_tokens_to_string(current_term))\n",
    "    \n",
    "    # Clean predicted terms\n",
    "    \n",
    "    predicted_terms = [clean_term(term) for term in predicted_terms if clean_term(term)]\n",
    "    return predicted_terms\n",
    "\n",
    "\n",
    "print(\"✓ Inference function defined\")\n",
    "\n",
    "# Run inference on all dev sentences\n",
    "print(\"Running inference on dev set...\")\n",
    "bert_preds = []\n",
    "\n",
    "for i, sentence in enumerate(dev_sentences):\n",
    "    if i % 200 == 0:\n",
    "        print(f\"  Processing {i}/{len(dev_sentences)}\")\n",
    "    \n",
    "    predicted_terms = perform_inference(\n",
    "        inference_model,\n",
    "        inference_tokenizer,\n",
    "        preprocess_text(sentence[\"sentence_text\"]), #CHANGED\n",
    "        id2label\n",
    "    )\n",
    "    bert_preds.append(predicted_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a9127b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference on dev set...\n",
      "  Processing 0/577\n",
      "  Processing 200/577\n",
      "  Processing 400/577\n",
      "✓ Inference completed: 577 predictions\n"
     ]
    }
   ],
   "source": [
    "# Run inference on all dev sentences\n",
    "print(\"Running inference on dev set...\")\n",
    "bert_preds = []\n",
    "\n",
    "for i, sentence in enumerate(dev_sentences):\n",
    "    if i % 200 == 0:\n",
    "        print(f\"  Processing {i}/{len(dev_sentences)}\")\n",
    "    \n",
    "    predicted_terms = perform_inference(\n",
    "        inference_model,\n",
    "        inference_tokenizer,\n",
    "        preprocess_text(sentence[\"sentence_text\"]),\n",
    "        id2label\n",
    "    )\n",
    "    bert_preds.append(predicted_terms)\n",
    "\n",
    "print(f\"✓ Inference completed: {len(bert_preds)} predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "067a1d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BERT TOKEN CLASSIFICATION RESULTS\n",
      "============================================================\n",
      "\n",
      "Micro-averaged Metrics:\n",
      "  Precision: 0.7323\n",
      "  Recall:    0.7095\n",
      "  F1 Score:  0.7207\n",
      "  TP=320, FP=117, FN=131\n",
      "\n",
      "Type-level Metrics:\n",
      "  Type Precision: 0.6767\n",
      "  Type Recall:    0.6488\n",
      "  Type F1 Score:  0.6624\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Prepare gold standard and predictions for evaluation\n",
    "dev_gold = [s['terms'] for s in dev_sentences]\n",
    "\n",
    "# Evaluate using competition metrics\n",
    "precision, recall, f1, tp, fp, fn= micro_f1_score(dev_gold, bert_preds)\n",
    "type_precision, type_recall, type_f1 = type_f1_score(dev_gold, bert_preds)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BERT TOKEN CLASSIFICATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nMicro-averaged Metrics:\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall:    {recall:.4f}\")\n",
    "print(f\"  F1 Score:  {f1:.4f}\")\n",
    "print(f\"  TP={tp}, FP={fp}, FN={fn}\")\n",
    "\n",
    "print(\"\\nType-level Metrics:\")\n",
    "print(f\"  Type Precision: {type_precision:.4f}\")\n",
    "print(f\"  Type Recall:    {type_recall:.4f}\")\n",
    "print(f\"  Type F1 Score:  {type_f1:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b16150",
   "metadata": {},
   "source": [
    "BERT TOKEN CLASSIFICATION 3e-5\n",
    "\n",
    "Micro-averaged Metrics:\n",
    "  Precision: 0.7090\n",
    "  Recall:    0.6807\n",
    "  F1 Score:  0.6946\n",
    "  TP=307, FP=126, FN=144\n",
    "\n",
    "Type-level Metrics:\n",
    "  Type Precision: 0.6476\n",
    "  Type Recall:    0.6074\n",
    "  Type F1 Score:  0.6269"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d48e0c",
   "metadata": {},
   "source": [
    "bert_token_classification_extended            0.708         0.672     0.689           0.655        0.595    0.623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "96a1c3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved 577 predictions to predictions/subtask_a_dev_bert_token_classification_preds_extended_2e-5_changed.json\n"
     ]
    }
   ],
   "source": [
    "# Save predictions in competition format\n",
    "def save_predictions(predictions, sentences, output_path):\n",
    "    \"\"\"Save predictions in competition format.\"\"\"\n",
    "    output = {'data': []}\n",
    "    for pred, sent in zip(predictions, sentences):\n",
    "        output['data'].append({\n",
    "            'document_id': sent['document_id'],\n",
    "            'paragraph_id': sent['paragraph_id'],\n",
    "            'sentence_id': sent['sentence_id'],\n",
    "            'term_list': pred\n",
    "        })\n",
    "    \n",
    "    os.makedirs(os.path.dirname(output_path) or '.', exist_ok=True)\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(output, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"✓ Saved {len(predictions)} predictions to {output_path}\")\n",
    "\n",
    "\n",
    "save_predictions(bert_preds, dev_sentences, 'predictions/subtask_a_dev_bert_token_classification_preds_extended_2e-5_changed.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6f6fcc",
   "metadata": {},
   "source": [
    "## Example Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8465b3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Predictions:\n",
      "\n",
      "Sentence: il presente disciplinare per la gestione dei centri di raccolta comunali è stato redatto ai sensi e ...\n",
      "Gold terms: ['disciplina dei centri di raccolta dei rifiuti urbani raccolti in modo differenziato', 'disciplinare per la gestione dei centri di raccolta comunali']\n",
      "BERT predictions: ['disciplinare', 'gestione', 'centri di raccolta comunali', 'disciplina', 'centri di raccolta dei rifiuti urbani raccolti']\n",
      "✓ Correct: 0\n",
      "✗ Missed: 2\n",
      "✗ Wrong: 5\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: è un servizio supplementare di raccolta, rivolto a famiglie con bambini al di sotto dei 3 anni o con...\n",
      "Gold terms: ['raccolta']\n",
      "BERT predictions: ['raccolta']\n",
      "✓ Correct: 1\n",
      "✗ Missed: 0\n",
      "✗ Wrong: 0\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: ll servizio di raccolta dei rifiuti derivanti da sfalci e potature è gestito dalla buttol srl con il...\n",
      "Gold terms: ['servizio di raccolta dei rifiuti', 'sfalci e potature']\n",
      "BERT predictions: ['servizio di raccolta dei rifiuti derivanti da sfalci e potature']\n",
      "✓ Correct: 0\n",
      "✗ Missed: 2\n",
      "✗ Wrong: 1\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: #differenziati...\n",
      "Gold terms: ['differenziati']\n",
      "BERT predictions: ['differenziati']\n",
      "✓ Correct: 1\n",
      "✗ Missed: 0\n",
      "✗ Wrong: 0\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: multimateriale; sacchetto blu trasparente; lunedì giovedì...\n",
      "Gold terms: ['multimateriale', 'sacchetto trasparente']\n",
      "BERT predictions: ['multimateriale']\n",
      "✓ Correct: 1\n",
      "✗ Missed: 1\n",
      "✗ Wrong: 0\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show example predictions\n",
    "print(\"Example Predictions:\\n\")\n",
    "\n",
    "count = 0\n",
    "for i in range(len(dev_sentences)):\n",
    "    if len(dev_gold[i]) > 0 and count < 5:\n",
    "        print(f\"Sentence: {dev_sentences[i]['sentence_text'][:100]}...\")\n",
    "        print(f\"Gold terms: {dev_gold[i][:5]}\")\n",
    "        print(f\"BERT predictions: {bert_preds[i][:5]}\")\n",
    "        \n",
    "        correct = set(dev_gold[i]) & set(bert_preds[i])\n",
    "        missed = set(dev_gold[i]) - set(bert_preds[i])\n",
    "        wrong = set(bert_preds[i]) - set(dev_gold[i])\n",
    "        \n",
    "        print(f\"✓ Correct: {len(correct)}\")\n",
    "        print(f\"✗ Missed: {len(missed)}\")\n",
    "        print(f\"✗ Wrong: {len(wrong)}\")\n",
    "        print(\"-\"*80)\n",
    "        print()\n",
    "        \n",
    "        count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
