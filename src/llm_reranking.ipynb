{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a0f18a7",
   "metadata": {},
   "source": [
    "# LLM-based Reranking of Candidate Terms for ATE-IT (Subtask A)\n",
    "\n",
    "This notebook shows how to:\n",
    "\n",
    "1. Load the ensemble predictions from **BERT + spaCy + dictionary filter**  \n",
    "   (`subtask_a_dev_ensemble_bert_spacy_dictfilter.json`).\n",
    "2. (Optionally) Load the original **dev sentences** (to give context to the LLM).\n",
    "3. Call a **Gemini LLM** to **rerank and filter** candidate terms for each sentence.\n",
    "4. Save the new predictions in the **same competition format** (JSON with `data` â†’ `term_list`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b15a797",
   "metadata": {},
   "source": [
    "### Imports and basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1db6172b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Imports loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"âœ“ Imports loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "473a6078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working dir: c:\\Users\\super\\Documents\\UniPd\\ATA\\ATE-IT_SofiaMaule\\src\n",
      "Repo root          : c:\\Users\\super\\Documents\\UniPd\\ATA\\ATE-IT_SofiaMaule\n",
      "Predictions path   : c:\\Users\\super\\Documents\\UniPd\\ATA\\ATE-IT_SofiaMaule\\src\\predictions\\subtask_a_dev_ensemble_bert_2e-5_changed_spacy_dictfilter.json\n",
      "Dev sentences path : c:\\Users\\super\\Documents\\UniPd\\ATA\\ATE-IT_SofiaMaule\\data\\subtask_a_dev.json\n",
      "Output path        : c:\\Users\\super\\Documents\\UniPd\\ATA\\ATE-IT_SofiaMaule\\src\\predictions\\subtask_a_dev_ensemble_bert_2e-5_changed_reranked_llm.json\n"
     ]
    }
   ],
   "source": [
    "# Current working dir = .../ATE-IT_SofiaMaule/src\n",
    "CWD = Path.cwd()\n",
    "REPO_ROOT = CWD.parent  # .../ATE-IT_SofiaMaule\n",
    "\n",
    "PREDICTIONS_PATH = REPO_ROOT / \"src\" / \"predictions\" / \"subtask_a_dev_ensemble_bert_2e-5_changed_spacy_dictfilter.json\"\n",
    "DEV_SENTENCES_PATH = REPO_ROOT / \"data\" / \"subtask_a_dev.json\"\n",
    "OUTPUT_PATH = REPO_ROOT / \"src\" / \"predictions\" / \"subtask_a_dev_ensemble_bert_2e-5_changed_reranked_llm.json\"\n",
    "\n",
    "print(\"Current working dir:\", CWD)\n",
    "print(\"Repo root          :\", REPO_ROOT)\n",
    "print(\"Predictions path   :\", PREDICTIONS_PATH)\n",
    "print(\"Dev sentences path :\", DEV_SENTENCES_PATH)\n",
    "print(\"Output path        :\", OUTPUT_PATH)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c8e03f",
   "metadata": {},
   "source": [
    "### 3. Initialize GROQ  model\n",
    " with an API key stored in `.env` as `GROQI_API_KEY`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce68e400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Groq client initialized\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load env\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "if not api_key:\n",
    "    raise RuntimeError(\"GROQ_API_KEY not found in .env\")\n",
    "\n",
    "client = Groq(api_key=api_key)\n",
    "\n",
    "print(\"âœ“ Groq client initialized\")\n",
    "\n",
    "# Choose a Groq-supported model\n",
    "#model_name = \"openai/gpt-oss-20b\"\n",
    "model_name = \"openai/gpt-oss-120b\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d541283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 577 prediction entries\n",
      "Loaded 577 dev sentences\n"
     ]
    }
   ],
   "source": [
    "# Load predictions\n",
    "\n",
    "with open(PREDICTIONS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    ensemble_pred = json.load(f)\n",
    "\n",
    "# Sanity check that the top-level key is \"data\"\n",
    "assert \"data\" in ensemble_pred, \"Unexpected format: 'data' key not found in predictions JSON\"\n",
    "\n",
    "print(f\"Loaded {len(ensemble_pred['data'])} prediction entries\")\n",
    "\n",
    "#  Load dev sentences\n",
    "\n",
    "if DEV_SENTENCES_PATH.exists():\n",
    "    with open(DEV_SENTENCES_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        dev_sentences = json.load(f)\n",
    "    assert \"data\" in dev_sentences, \"Unexpected format: 'data' key not found in dev sentences JSON\"\n",
    "    print(f\"Loaded {len(dev_sentences['data'])} dev sentences\")\n",
    "else:\n",
    "    dev_sentences = None\n",
    "    print(\"Dev sentences file not found. Reranking will use only candidate terms, without sentence context.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b83f9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 577 sentence texts\n"
     ]
    }
   ],
   "source": [
    "# Build index: (doc, par, sent) -> sentence_text\n",
    "\n",
    "sentence_index: Dict[Tuple[str, int, int], str] = {}\n",
    "\n",
    "if dev_sentences is not None:\n",
    "    for entry in dev_sentences[\"data\"]:\n",
    "        key = (entry[\"document_id\"], entry[\"paragraph_id\"], entry[\"sentence_id\"])\n",
    "        sentence_index[key] = entry[\"sentence_text\"]\n",
    "\n",
    "    print(f\"Indexed {len(sentence_index)} sentence texts\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff8ab8b",
   "metadata": {},
   "source": [
    "### Define the LLM prompt for reranking\n",
    "\n",
    "We now define a **prompt template**. For each sentence, we will provide:\n",
    "\n",
    "- The **sentence text** (if available).\n",
    "- The list of **candidate terms** from BERT+spaCy.\n",
    "\n",
    "We ask the LLM to:\n",
    "\n",
    "1. Decide which candidates are **real domain-relevant terms** in context.\n",
    "2. Assign a **score** in `[0, 1]` (e.g., 0.0â€“1.0) representing term quality.\n",
    "3. Return a **strict JSON** object with this structure:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"reranked_terms\": [\n",
    "    {\"term\": \"centri di raccolta\", \"score\": 0.95, \"keep\": true},\n",
    "    {\"term\": \"disciplina\", \"score\": 0.80, \"keep\": true},\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "Then we will:\n",
    "- Keep only items where keep == true.\n",
    "- Sort them by score descending.\n",
    "- Use the sorted term strings as the new term_list for that sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40defbda",
   "metadata": {},
   "source": [
    "## 1. Domain-aware reranking prompt\n",
    "\n",
    "We enrich the system prompt with **explicit domain knowledge** and tell the model that its scores will be combined with a rule-based domain scorer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13b9b6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "system_prompt_rerank = \"\"\"\n",
    "You are an automatic term extraction *reranking* agent for Italian municipal waste management texts.\n",
    "\n",
    "You will receive:\n",
    "- one sentence in Italian, and\n",
    "- a list of candidate terms extracted by a baseline system.\n",
    "\n",
    "Your task:\n",
    "- For each candidate term, decide if it is a good domain-relevant term in the context of the sentence.\n",
    "- Assign a relevance score between 0.0 and 1.0 (higher = better).\n",
    "- Decide whether to keep or discard each candidate.\n",
    "\n",
    "--------------------------------\n",
    "DOMAIN KNOWLEDGE (WASTE MANAGEMENT)\n",
    "--------------------------------\n",
    "\n",
    "Valid waste management terms typically include:\n",
    "\n",
    "1) Waste types and materials\n",
    "- rifiuti, rifiuti urbani, rifiuti ingombranti, rifiuti pericolosi, rifiuti organici\n",
    "- carta, cartone, plastica, vetro, metalli, alluminio, banda stagnata, legno, tessili\n",
    "- RAEE / R.A.E.E., toner, oli esausti\n",
    "\n",
    "2) Services, infrastructures, processes\n",
    "- raccolta differenziata, raccolta porta a porta, modalitÃ  di raccolta, modalitÃ  di conferimento\n",
    "- servizio di raccolta, servizio di igiene urbana\n",
    "- centro di raccolta, centri di raccolta comunali, isola ecologica, ecocentro, piattaforma ecologica\n",
    "- impianto di trattamento rifiuti, impianto di smaltimento, discarica, compostaggio\n",
    "\n",
    "3) Regulations, tariffs, administrative terms\n",
    "- regolamento, disciplinare, disciplinare per la gestione dei centri di raccolta comunali\n",
    "- tassa rifiuti, TARI, tariffa puntuale, tariffe\n",
    "- utenti, utenze domestiche, utenze non domestiche\n",
    "\n",
    "4) Action verbs and phrases that are domain terms\n",
    "- conferire, conferiti, vanno conferiti, conferimento, modalitÃ  di conferimento\n",
    "- depositare, deposito, conferire i rifiuti, conferire i rifiuti vegetali\n",
    "\n",
    "Non-terms are:\n",
    "- generic function words (es. \"e\", \"di\", \"per\", \"che\")\n",
    "- pure numbers or dates not part of a waste term\n",
    "- person names, city names, street names (unless part of an official waste management service)\n",
    "- clearly truncated fragments (e.g., \"dei\", \"oo\", \"r\" alone)\n",
    "\n",
    "--------------------------------\n",
    "OUTPUT FORMAT (STRICT JSON)\n",
    "--------------------------------\n",
    "\n",
    "You MUST output ONLY a JSON object with this exact structure:\n",
    "\n",
    "{\n",
    "  \"reranked_terms\": [\n",
    "    {\"term\": \"...\", \"score\": 0.0, \"keep\": true or false},\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- Do not add new terms that are not in the candidate list.\n",
    "- Do not modify the spelling of the candidates.\n",
    "- If a candidate looks truncated or not a full concept, set \"keep\": false and give it a low score.\n",
    "- If no candidate is good, you may return an empty list: \"reranked_terms\": [].\n",
    "- The JSON must be valid and parseable by Python's json.loads().\n",
    "\n",
    "Your scores will be later combined with a rule-based domain scorer, so:\n",
    "- assign *higher* scores to candidates that clearly match the domain knowledge above,\n",
    "- and *lower* scores to generic or borderline expressions.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def build_llm_input(\n",
    "    sentence_text: Optional[str],\n",
    "    candidates: List[str]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Build the USER part of the prompt sent to Gemini, consistent with the 'System: ... / User: ...' pattern.\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "\n",
    "    if sentence_text is not None:\n",
    "        lines.append(f\"Sentence (Italian): {sentence_text}\")\n",
    "    else:\n",
    "        lines.append(\"Sentence: [NOT AVAILABLE]\")\n",
    "\n",
    "    lines.append(\"Candidate terms:\")\n",
    "    for t in candidates:\n",
    "        lines.append(f\"- {t}\")\n",
    "\n",
    "    lines.append(\n",
    "        \"\\nNow produce ONLY the JSON object with the structure described in the system instructions.\"\n",
    "    )\n",
    "\n",
    "    return \"\\n\".join(lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e703d5",
   "metadata": {},
   "source": [
    "##  Rule-based domain scorer (hybrid with LLM)\n",
    "\n",
    "We now define a small **domain vocabulary** and a function that adjusts the LLM scores:\n",
    "\n",
    "- boost terms that match domain patterns (TARI, RAEE, centro di raccolta, conferire, ecc.)\n",
    "- penalize generic or clearly bad terms\n",
    "- detect truncated phrases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3222a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain vocab + helpers for hybrid scoring\n",
    "\n",
    "import math\n",
    "\n",
    "# You can refine / expand this over time\n",
    "DOMAIN_STRONG_TERMS = {\n",
    "    \"rifiuti urbani\",\n",
    "    \"rifiuti ingombranti\",\n",
    "    \"rifiuti pericolosi\",\n",
    "    \"raccolta differenziata\",\n",
    "    \"raccolta porta a porta\",\n",
    "    \"servizio di raccolta\",\n",
    "    \"servizio di igiene urbana\",\n",
    "    \"centro di raccolta\",\n",
    "    \"centri di raccolta comunali\",\n",
    "    \"isola ecologica\",\n",
    "    \"ecocentro\",\n",
    "    \"piattaforma ecologica\",\n",
    "    \"impianto di trattamento rifiuti\",\n",
    "    \"impianto di smaltimento\",\n",
    "    \"tassa rifiuti\",\n",
    "    \"tari\",\n",
    "    \"disciplinare\",\n",
    "    \"regolamento\",\n",
    "    \"utenze domestiche\",\n",
    "    \"utenze non domestiche\",\n",
    "    \"modalitÃ  di conferimento\",\n",
    "    \"modalitÃ  di raccolta\",\n",
    "    \"conferimento\",\n",
    "    \"conferire\",\n",
    "    \"conferiti\",\n",
    "    \"vanno conferiti\",\n",
    "}\n",
    "\n",
    "# Substring-based signals (if term contains one of these, it's likely relevant)\n",
    "DOMAIN_KEYWORD_SUBSTRINGS = [\n",
    "    \"rifiuti\",\n",
    "    \"raccolta\",\n",
    "    \"confer\",\n",
    "    \"ecologic\",\n",
    "    \"centro di raccolta\",\n",
    "    \"impianto\",\n",
    "    \"tariff\",\n",
    "    \"tassa\",\n",
    "    \"tari\",\n",
    "    \"raee\",\n",
    "    \"isola ecologica\",\n",
    "]\n",
    "\n",
    "# Terms that are often too generic if used alone\n",
    "GENERIC_WEAK_TERMS = {\n",
    "    \"rifiuti\",\n",
    "    \"plastica\",\n",
    "    \"carta\",\n",
    "    \"vetro\",\n",
    "    \"metalli\",\n",
    "    \"alluminio\",\n",
    "    \"legno\",\n",
    "}\n",
    "\n",
    "FUNCTION_ENDINGS = {\"di\", \"dei\", \"degli\", \"delle\", \"del\", \"e\", \"o\", \"ed\", \"al\", \"allo\", \"alla\", \"ai\", \"agli\", \"alle\"}\n",
    "\n",
    "\n",
    "def normalize_term_text(t: str) -> str:\n",
    "    return \" \".join(t.lower().strip().split())\n",
    "\n",
    "\n",
    "def looks_truncated(term: str) -> bool:\n",
    "    \"\"\"\n",
    "    Heuristic: terms that end with a function word or are extremely short / odd.\n",
    "    \"\"\"\n",
    "    t = normalize_term_text(term)\n",
    "    tokens = t.split()\n",
    "    if len(tokens) == 0:\n",
    "        return True\n",
    "    if len(tokens) == 1 and tokens[0] in {\"r\", \"oo\"}:\n",
    "        return True\n",
    "    if tokens[-1] in FUNCTION_ENDINGS:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def contains_domain_substring(term: str) -> bool:\n",
    "    t = normalize_term_text(term)\n",
    "    return any(sub in t for sub in DOMAIN_KEYWORD_SUBSTRINGS)\n",
    "\n",
    "\n",
    "# Hyperparameters for hybrid scoring\n",
    "LLM_WEIGHT = 0.7       # how much we trust the LLM score\n",
    "RULE_WEIGHT = 0.3      # how much we trust the rules\n",
    "KEEP_THRESHOLD = 0.35  # final score threshold to keep a term\n",
    "\n",
    "\n",
    "def hybrid_score_term(term: str, llm_score: float, sentence_text: str | None = None) -> tuple[float, bool]:\n",
    "    \"\"\"\n",
    "    Combine LLM score with domain-driven rule-based score.\n",
    "\n",
    "    Returns:\n",
    "      final_score, keep_flag\n",
    "    \"\"\"\n",
    "    t_norm = normalize_term_text(term)\n",
    "    base_rule_score = 0.5  # neutral baseline\n",
    "\n",
    "    # Strong domain terms â†’ boost\n",
    "    if t_norm in {normalize_term_text(x) for x in DOMAIN_STRONG_TERMS}:\n",
    "        base_rule_score += 0.3\n",
    "\n",
    "    # Contains domain-ish substring â†’ slight boost\n",
    "    if contains_domain_substring(term):\n",
    "        base_rule_score += 0.15\n",
    "\n",
    "    # Weak generic terms used alone â†’ penalty\n",
    "    if t_norm in GENERIC_WEAK_TERMS and len(t_norm.split()) == 1:\n",
    "        base_rule_score -= 0.2\n",
    "\n",
    "    # Truncated or clearly bad-looking â†’ strong penalty\n",
    "    if looks_truncated(term):\n",
    "        base_rule_score -= 0.4\n",
    "\n",
    "    # Clip rule score to [0, 1]\n",
    "    rule_score = max(0.0, min(1.0, base_rule_score))\n",
    "\n",
    "    # Combine LLM + rules\n",
    "    llm_score_clipped = max(0.0, min(1.0, llm_score))\n",
    "    final_score = LLM_WEIGHT * llm_score_clipped + RULE_WEIGHT * rule_score\n",
    "\n",
    "    # Decision to keep\n",
    "    keep_flag = final_score >= KEEP_THRESHOLD\n",
    "\n",
    "    # Safety: if LLM says keep AND rule_score > 0.7, force keep even if threshold borderline\n",
    "    if llm_score_clipped >= 0.6 and rule_score >= 0.7:\n",
    "        keep_flag = True\n",
    "\n",
    "    return final_score, keep_flag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aff66c",
   "metadata": {},
   "source": [
    "###  LLM call helper\n",
    "\n",
    "We now define a helper function that:\n",
    "\n",
    "1. Builds the prompt text.\n",
    "2. Calls `model.generate_content(...)`.\n",
    "3. Extracts and parses the JSON part.\n",
    "4. Returns a **list of dicts** (`{\"term\", \"score\", \"keep\"}`) or an empty list if something fails.\n",
    "\n",
    "\n",
    "We call Groq as before, but then **post-process each term** with `hybrid_score_term(...)` \n",
    "and overwrite both `score` and `keep` according to the hybrid logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6dc2a651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ” REPLACE your current `call_llm_rerank` with this one (Groq + hybrid)\n",
    "\n",
    "def call_llm_rerank(\n",
    "    sentence_text: Optional[str],\n",
    "    candidates: List[str],\n",
    "    dry_run: bool = False\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Call Groq LLM to get base scores, then refine them with domain-based rules.\n",
    "\n",
    "    Returns list of:\n",
    "      {\"term\": str, \"score\": float, \"keep\": bool}\n",
    "    \"\"\"\n",
    "    if not candidates:\n",
    "        return []\n",
    "\n",
    "    user_prompt = build_llm_input(sentence_text, candidates)\n",
    "\n",
    "    # Dry-run option to skip API call\n",
    "    if dry_run:\n",
    "        hybrid = []\n",
    "        for c in candidates:\n",
    "            base = 0.5\n",
    "            final_score, keep_flag = hybrid_score_term(c, base, sentence_text)\n",
    "            hybrid.append({\"term\": c, \"score\": final_score, \"keep\": keep_flag})\n",
    "        return hybrid\n",
    "\n",
    "    try:\n",
    "        # Call Groq LLM â€” ChatCompletion style\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt_rerank},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "            temperature=0.15,\n",
    "        )\n",
    "\n",
    "        text = response.choices[0].message.content.strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"âš ï¸ LLM call failed:\", e)\n",
    "        # Fallback: keep all with rule-based neutral score\n",
    "        fallback = []\n",
    "        for c in candidates:\n",
    "            base = 0.5\n",
    "            final_score, keep_flag = hybrid_score_term(c, base, sentence_text)\n",
    "            fallback.append({\"term\": c, \"score\": final_score, \"keep\": keep_flag})\n",
    "        return fallback\n",
    "\n",
    "    # Parse JSON returned by LLM\n",
    "    try:\n",
    "        data = json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        # Try to extract substring containing JSON\n",
    "        try:\n",
    "            start = text.index(\"{\")\n",
    "            end = text.rindex(\"}\") + 1\n",
    "            data = json.loads(text[start:end])\n",
    "        except Exception as e2:\n",
    "            print(\"âš ï¸ JSON parsing failed, using fallback:\", e2)\n",
    "            fallback = []\n",
    "            for c in candidates:\n",
    "                base = 0.5\n",
    "                final_score, keep_flag = hybrid_score_term(c, base, sentence_text)\n",
    "                fallback.append({\"term\": c, \"score\": final_score, \"keep\": keep_flag})\n",
    "            return fallback\n",
    "\n",
    "    reranked = data.get(\"reranked_terms\", [])\n",
    "    cleaned: List[Dict[str, Any]] = []\n",
    "\n",
    "    # First, trust only items that refer to original candidates\n",
    "    for item in reranked:\n",
    "        term = item.get(\"term\")\n",
    "        if term is None or term not in candidates:\n",
    "            continue\n",
    "        try:\n",
    "            llm_score = float(item.get(\"score\", 0.0))\n",
    "        except Exception:\n",
    "            llm_score = 0.0\n",
    "        # LLM keep flag is advisory; hybrid logic will finalize\n",
    "        cleaned.append({\"term\": term, \"score\": llm_score})\n",
    "\n",
    "    # If LLM returned nothing usable, fall back to neutral scores\n",
    "    if not cleaned:\n",
    "        cleaned = [{\"term\": c, \"score\": 0.5} for c in candidates]\n",
    "\n",
    "    # Apply hybrid domain scoring\n",
    "    hybrid_results: List[Dict[str, Any]] = []\n",
    "    for item in cleaned:\n",
    "        term = item[\"term\"]\n",
    "        llm_score = item[\"score\"]\n",
    "        final_score, keep_flag = hybrid_score_term(term, llm_score, sentence_text)\n",
    "        hybrid_results.append(\n",
    "            {\"term\": term, \"score\": final_score, \"keep\": keep_flag}\n",
    "        )\n",
    "\n",
    "    return hybrid_results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cec5f5",
   "metadata": {},
   "source": [
    "### Apply reranking to all sentences\n",
    "\n",
    "We now:\n",
    "\n",
    "1. Iterate over each entry in `ensemble_pred[\"data\"]`.\n",
    "2. Extract:\n",
    "   - `document_id`, `paragraph_id`, `sentence_id`\n",
    "   - `term_list` (candidate terms)\n",
    "3. Look up the **sentence text** using `sentence_index` (if available).\n",
    "4. Call `call_llm_rerank(...)`.\n",
    "5. Filter and sort terms:\n",
    "   - Keep only `keep == True`.\n",
    "   - Sort by `score` descending.\n",
    "6. Build a new `data` list with the **same structure** as the original predictions, but with reranked `term_list`.\n",
    "\n",
    "We also add a `dry_run` option for debugging without making real API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5010b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Apply reranking\n",
    "\n",
    "def rerank_all_entries(\n",
    "    predictions: Dict[str, Any],\n",
    "    sentence_index: Dict[Tuple[str, int, int], str],\n",
    "    use_sentence_context: bool = True,\n",
    "    dry_run: bool = False,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Apply LLM reranking to all entries in predictions[\"data\"].\n",
    "\n",
    "    Returns a new dict with the same structure, but reranked term_list.\n",
    "    \"\"\"\n",
    "    new_data = []\n",
    "\n",
    "    for entry in tqdm(predictions[\"data\"], desc=\"Reranking terms\"):\n",
    "        doc_id = entry[\"document_id\"]\n",
    "        par_id = entry[\"paragraph_id\"]\n",
    "        sent_id = entry[\"sentence_id\"]\n",
    "        candidates = entry.get(\"term_list\", [])\n",
    "\n",
    "        key = (doc_id, par_id, sent_id)\n",
    "        sentence_text = sentence_index.get(key) if (use_sentence_context and sentence_index) else None\n",
    "\n",
    "        reranked_items = call_llm_rerank(\n",
    "            sentence_text=sentence_text,\n",
    "            candidates=candidates,\n",
    "            dry_run=dry_run,\n",
    "        )\n",
    "\n",
    "        # Filter by keep==True and sort by score (descending)\n",
    "        kept = [item for item in reranked_items if item[\"keep\"]]\n",
    "        kept_sorted = sorted(kept, key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "        new_term_list = [item[\"term\"] for item in kept_sorted]\n",
    "\n",
    "        new_entry = {\n",
    "            \"document_id\": doc_id,\n",
    "            \"paragraph_id\": par_id,\n",
    "            \"sentence_id\": sent_id,\n",
    "            \"term_list\": new_term_list,\n",
    "        }\n",
    "        new_data.append(new_entry)\n",
    "\n",
    "    return {\"data\": new_data}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab626749",
   "metadata": {},
   "source": [
    "## 8. Quick dry-run (no real LLM calls)\n",
    "\n",
    "Before spending tokens, we can test the pipeline in **dry_run** mode, which:\n",
    "\n",
    "- Skips real LLM calls.\n",
    "- Assigns a dummy score of 0.5 to every candidate.\n",
    "- Keeps all terms, but goes through the whole structure.\n",
    "\n",
    "This is useful to detect path / format issues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63a8157b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"document_id\": \"doc_praiano_07\",\n",
      "    \"paragraph_id\": 32,\n",
      "    \"sentence_id\": 7,\n",
      "    \"term_list\": []\n",
      "  },\n",
      "  {\n",
      "    \"document_id\": \"doc_caserta_06\",\n",
      "    \"paragraph_id\": 3,\n",
      "    \"sentence_id\": 1,\n",
      "    \"term_list\": [\n",
      "      \"disciplinare per la gestione dei centri di raccolta comunali\",\n",
      "      \"centri di raccolta dei rifiuti urbani raccolti in\"\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 8. Dry run test on a small subset\n",
    "\n",
    "test_predictions = {\n",
    "    \"data\": ensemble_pred[\"data\"][:5]  # only first 5 entries for a quick test\n",
    "}\n",
    "\n",
    "reranked_test = rerank_all_entries(\n",
    "    predictions=test_predictions,\n",
    "    sentence_index=sentence_index,\n",
    "    use_sentence_context=True,\n",
    "    dry_run=True,   # <-- no real API calls\n",
    ")\n",
    "\n",
    "print(json.dumps(reranked_test[\"data\"][:2], indent=2, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd386aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  12%|â–ˆâ–        | 70/577 [00:22<02:20,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199457, Requested 795. Please try again in 1m48.864s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199457, Requested 837. Please try again in 2m7.008s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199457, Requested 822. Please try again in 2m0.527999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199457, Requested 809. Please try again in 1m54.912s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  13%|â–ˆâ–Ž        | 74/577 [00:22<01:42,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199457, Requested 804. Please try again in 1m52.752s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199457, Requested 810. Please try again in 1m55.344s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199457, Requested 806. Please try again in 1m53.616s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199457, Requested 778. Please try again in 1m41.52s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  15%|â–ˆâ–        | 85/577 [00:22<00:48, 10.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199456, Requested 910. Please try again in 2m38.112s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199456, Requested 788. Please try again in 1m45.408s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199456, Requested 781. Please try again in 1m42.384s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199456, Requested 822. Please try again in 2m0.095999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  16%|â–ˆâ–‹        | 94/577 [00:22<00:30, 15.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199456, Requested 814. Please try again in 1m56.64s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199456, Requested 798. Please try again in 1m49.728s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199456, Requested 833. Please try again in 2m4.848s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199456, Requested 793. Please try again in 1m47.568s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  18%|â–ˆâ–Š        | 106/577 [00:23<00:19, 24.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199455, Requested 876. Please try again in 2m22.992s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199455, Requested 850. Please try again in 2m11.76s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199455, Requested 808. Please try again in 1m53.616s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199455, Requested 799. Please try again in 1m49.728s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  19%|â–ˆâ–‰        | 111/577 [00:23<00:16, 27.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199455, Requested 812. Please try again in 1m55.344s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199455, Requested 782. Please try again in 1m42.384s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199455, Requested 805. Please try again in 1m52.32s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199455, Requested 781. Please try again in 1m41.952s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199454, Requested 801. Please try again in 1m50.16s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  21%|â–ˆâ–ˆ        | 122/577 [00:23<00:16, 28.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199454, Requested 798. Please try again in 1m48.864s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199454, Requested 832. Please try again in 2m3.552s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199454, Requested 791. Please try again in 1m45.84s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199454, Requested 861. Please try again in 2m16.08s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  22%|â–ˆâ–ˆâ–       | 127/577 [00:23<00:15, 29.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199454, Requested 788. Please try again in 1m44.544s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199454, Requested 800. Please try again in 1m49.728s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199454, Requested 830. Please try again in 2m2.688s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199453, Requested 818. Please try again in 1m57.072s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  23%|â–ˆâ–ˆâ–Ž       | 134/577 [00:23<00:12, 36.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199453, Requested 889. Please try again in 2m27.744s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199453, Requested 792. Please try again in 1m45.84s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199453, Requested 815. Please try again in 1m55.776s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199453, Requested 777. Please try again in 1m39.36s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  25%|â–ˆâ–ˆâ–Œ       | 147/577 [00:24<00:11, 37.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199453, Requested 798. Please try again in 1m48.432s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199453, Requested 782. Please try again in 1m41.52s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199453, Requested 789. Please try again in 1m44.544s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199453, Requested 777. Please try again in 1m39.36s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  28%|â–ˆâ–ˆâ–Š       | 159/577 [00:24<00:09, 45.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199452, Requested 790. Please try again in 1m44.544s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199452, Requested 799. Please try again in 1m48.432s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199452, Requested 831. Please try again in 2m2.256s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199452, Requested 801. Please try again in 1m49.296s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  29%|â–ˆâ–ˆâ–Š       | 165/577 [00:24<00:09, 43.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199452, Requested 817. Please try again in 1m56.208s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199452, Requested 784. Please try again in 1m41.952s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199452, Requested 788. Please try again in 1m43.68s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199452, Requested 817. Please try again in 1m56.208s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  30%|â–ˆâ–ˆâ–ˆ       | 175/577 [00:24<00:09, 41.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199451, Requested 819. Please try again in 1m56.64s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199451, Requested 788. Please try again in 1m43.248s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199451, Requested 796. Please try again in 1m46.704s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199451, Requested 838. Please try again in 2m4.848s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  31%|â–ˆâ–ˆâ–ˆ       | 180/577 [00:25<00:11, 34.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199451, Requested 803. Please try again in 1m49.728s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199451, Requested 819. Please try again in 1m56.64s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199451, Requested 774. Please try again in 1m37.199999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199451, Requested 784. Please try again in 1m41.52s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 190/577 [00:25<00:09, 40.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199450, Requested 820. Please try again in 1m56.64s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199450, Requested 810. Please try again in 1m52.32s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199450, Requested 794. Please try again in 1m45.408s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199450, Requested 777. Please try again in 1m38.064s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199450, Requested 798. Please try again in 1m47.136s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 206/577 [00:25<00:07, 51.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199450, Requested 792. Please try again in 1m44.544s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199450, Requested 843. Please try again in 2m6.576s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199450, Requested 785. Please try again in 1m41.52s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199450, Requested 946. Please try again in 2m51.072s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 212/577 [00:25<00:08, 42.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199449, Requested 787. Please try again in 1m41.952s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199449, Requested 794. Please try again in 1m44.976s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199449, Requested 828. Please try again in 1m59.664s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199449, Requested 786. Please try again in 1m41.52s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 217/577 [00:25<00:09, 38.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199449, Requested 774. Please try again in 1m36.336s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199449, Requested 794. Please try again in 1m44.976s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199449, Requested 805. Please try again in 1m49.728s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199449, Requested 788. Please try again in 1m42.384s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 245/577 [00:26<00:04, 80.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199448, Requested 807. Please try again in 1m50.16s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199448, Requested 780. Please try again in 1m38.496s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199448, Requested 802. Please try again in 1m48s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199448, Requested 811. Please try again in 1m51.887999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 266/577 [00:26<00:04, 69.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199448, Requested 786. Please try again in 1m41.088s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199448, Requested 848. Please try again in 2m7.872s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199448, Requested 782. Please try again in 1m39.36s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199448, Requested 800. Please try again in 1m47.136s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199448, Requested 803. Please try again in 1m48.432s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199447, Requested 794. Please try again in 1m44.112s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199447, Requested 787. Please try again in 1m41.088s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199447, Requested 827. Please try again in 1m58.368s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199447, Requested 849. Please try again in 2m7.872s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 281/577 [00:26<00:05, 55.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199447, Requested 851. Please try again in 2m8.735999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199447, Requested 798. Please try again in 1m45.84s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199447, Requested 797. Please try again in 1m45.408s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199447, Requested 782. Please try again in 1m38.928s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199446, Requested 1004. Please try again in 3m14.399999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 294/577 [00:27<00:06, 46.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199446, Requested 878. Please try again in 2m19.968s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199446, Requested 818. Please try again in 1m54.048s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199446, Requested 873. Please try again in 2m17.808s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199446, Requested 955. Please try again in 2m53.232s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199446, Requested 789. Please try again in 1m41.52s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 303/577 [00:27<00:05, 50.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199446, Requested 797. Please try again in 1m44.976s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199446, Requested 783. Please try again in 1m38.928s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199445, Requested 782. Please try again in 1m38.064s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199445, Requested 918. Please try again in 2m36.816s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199445, Requested 813. Please try again in 1m51.455999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 320/577 [00:27<00:04, 54.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199445, Requested 1000. Please try again in 3m12.24s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199445, Requested 812. Please try again in 1m51.023999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199445, Requested 781. Please try again in 1m37.631999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199445, Requested 788. Please try again in 1m40.656s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 339/577 [00:27<00:03, 69.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199445, Requested 788. Please try again in 1m40.656s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199444, Requested 793. Please try again in 1m42.384s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199444, Requested 792. Please try again in 1m41.952s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199444, Requested 783. Please try again in 1m38.064s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199444, Requested 783. Please try again in 1m38.064s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 347/577 [00:27<00:03, 64.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199444, Requested 780. Please try again in 1m36.767999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199444, Requested 805. Please try again in 1m47.568s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199444, Requested 775. Please try again in 1m34.608s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199444, Requested 817. Please try again in 1m52.752s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 361/577 [00:28<00:03, 55.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199443, Requested 826. Please try again in 1m56.208s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199443, Requested 807. Please try again in 1m48s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199443, Requested 793. Please try again in 1m41.952s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199443, Requested 787. Please try again in 1m39.36s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 368/577 [00:28<00:04, 47.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199443, Requested 791. Please try again in 1m41.088s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199443, Requested 788. Please try again in 1m39.792s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199443, Requested 780. Please try again in 1m36.336s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199443, Requested 853. Please try again in 2m7.872s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 379/577 [00:28<00:04, 45.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199443, Requested 845. Please try again in 2m4.416s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199442, Requested 775. Please try again in 1m33.744s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199442, Requested 786. Please try again in 1m38.496s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199442, Requested 817. Please try again in 1m51.887999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 391/577 [00:28<00:03, 50.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199442, Requested 779. Please try again in 1m35.472s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199442, Requested 958. Please try again in 2m52.8s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199442, Requested 829. Please try again in 1m57.072s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199442, Requested 823. Please try again in 1m54.48s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 397/577 [00:29<00:04, 40.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199442, Requested 788. Please try again in 1m39.36s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199441, Requested 805. Please try again in 1m46.271999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199441, Requested 828. Please try again in 1m56.208s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199441, Requested 877. Please try again in 2m17.376s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199441, Requested 837. Please try again in 2m0.095999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 407/577 [00:29<00:04, 38.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199441, Requested 851. Please try again in 2m6.143999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199441, Requested 820. Please try again in 1m52.752s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199441, Requested 803. Please try again in 1m45.408s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199441, Requested 791. Please try again in 1m40.224s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 421/577 [00:29<00:03, 50.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199440, Requested 802. Please try again in 1m44.544s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199440, Requested 796. Please try again in 1m41.952s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199440, Requested 833. Please try again in 1m57.936s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199440, Requested 790. Please try again in 1m39.36s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 433/577 [00:29<00:02, 53.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199440, Requested 798. Please try again in 1m42.816s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199440, Requested 798. Please try again in 1m42.816s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199440, Requested 794. Please try again in 1m41.088s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199440, Requested 914. Please try again in 2m32.928s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 443/577 [00:30<00:02, 58.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199439, Requested 776. Please try again in 1m32.88s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199439, Requested 907. Please try again in 2m29.472s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199439, Requested 784. Please try again in 1m36.336s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199439, Requested 795. Please try again in 1m41.088s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 456/577 [00:30<00:02, 56.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199439, Requested 802. Please try again in 1m44.112s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199439, Requested 780. Please try again in 1m34.608s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199439, Requested 783. Please try again in 1m35.904s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199439, Requested 884. Please try again in 2m19.536s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199438, Requested 874. Please try again in 2m14.783999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199438, Requested 789. Please try again in 1m38.064s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199438, Requested 861. Please try again in 2m9.168s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199438, Requested 788. Please try again in 1m37.631999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 462/577 [00:30<00:02, 39.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199438, Requested 780. Please try again in 1m34.176s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199438, Requested 817. Please try again in 1m50.16s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199438, Requested 823. Please try again in 1m52.752s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199438, Requested 794. Please try again in 1m40.224s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 476/577 [00:30<00:02, 44.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199438, Requested 791. Please try again in 1m38.928s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199437, Requested 836. Please try again in 1m57.936s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199437, Requested 782. Please try again in 1m34.608s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199437, Requested 781. Please try again in 1m34.176s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 489/577 [00:31<00:01, 48.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199437, Requested 788. Please try again in 1m37.199999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199437, Requested 808. Please try again in 1m45.84s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199437, Requested 779. Please try again in 1m33.312s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199437, Requested 788. Please try again in 1m37.199999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 495/577 [00:31<00:02, 40.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199437, Requested 782. Please try again in 1m34.608s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199436, Requested 780. Please try again in 1m33.312s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199436, Requested 800. Please try again in 1m41.952s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199436, Requested 795. Please try again in 1m39.792s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 500/577 [00:31<00:02, 33.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199436, Requested 790. Please try again in 1m37.631999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199436, Requested 829. Please try again in 1m54.48s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199436, Requested 929. Please try again in 2m37.68s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199436, Requested 804. Please try again in 1m43.68s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 511/577 [00:31<00:01, 40.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199436, Requested 815. Please try again in 1m48.432s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199435, Requested 786. Please try again in 1m35.472s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199435, Requested 819. Please try again in 1m49.728s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199435, Requested 807. Please try again in 1m44.544s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 516/577 [00:31<00:01, 42.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199435, Requested 802. Please try again in 1m42.384s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199435, Requested 783. Please try again in 1m34.176s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199435, Requested 848. Please try again in 2m2.256s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199435, Requested 789. Please try again in 1m36.767999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 521/577 [00:32<00:01, 36.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199435, Requested 812. Please try again in 1m46.704s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199434, Requested 792. Please try again in 1m37.631999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199434, Requested 792. Please try again in 1m37.631999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199434, Requested 788. Please try again in 1m35.904s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 526/577 [00:32<00:01, 33.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199434, Requested 784. Please try again in 1m34.176s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199434, Requested 836. Please try again in 1m56.64s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199434, Requested 795. Please try again in 1m38.928s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 530/577 [00:32<00:01, 25.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199434, Requested 790. Please try again in 1m36.767999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199433, Requested 806. Please try again in 1m43.248s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199433, Requested 798. Please try again in 1m39.792s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 539/577 [00:32<00:01, 23.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199433, Requested 796. Please try again in 1m38.928s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199433, Requested 811. Please try again in 1m45.408s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199433, Requested 797. Please try again in 1m39.36s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 542/577 [00:33<00:01, 19.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199432, Requested 826. Please try again in 1m51.455999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199432, Requested 784. Please try again in 1m33.312s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199432, Requested 789. Please try again in 1m35.472s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 547/577 [00:33<00:01, 21.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199432, Requested 798. Please try again in 1m39.36s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199432, Requested 822. Please try again in 1m49.728s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199431, Requested 783. Please try again in 1m32.448s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 555/577 [00:33<00:00, 28.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199431, Requested 804. Please try again in 1m41.52s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199431, Requested 837. Please try again in 1m55.776s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199431, Requested 815. Please try again in 1m46.271999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 559/577 [00:33<00:00, 20.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199431, Requested 809. Please try again in 1m43.68s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199430, Requested 809. Please try again in 1m43.248s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199430, Requested 784. Please try again in 1m32.448s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 571/577 [00:34<00:00, 25.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199430, Requested 841. Please try again in 1m57.072s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199430, Requested 798. Please try again in 1m38.496s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199429, Requested 793. Please try again in 1m35.904s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 576/577 [00:34<00:00, 26.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199429, Requested 783. Please try again in 1m31.584s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199429, Requested 794. Please try again in 1m36.336s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "âš ï¸ LLM call failed: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01kab6qhfyf8frwbqaks6a2w25` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199429, Requested 864. Please try again in 2m6.576s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking terms: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 577/577 [00:34<00:00, 16.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Completed LLM reranking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 9. Full reranking with real LLM calls\n",
    "\n",
    "USE_SENTENCE_CONTEXT = True    # set to False if you don't have dev sentences\n",
    "DRY_RUN = False                # set to True if you want to test without API calls\n",
    "\n",
    "reranked_full = rerank_all_entries(\n",
    "    predictions=ensemble_pred,\n",
    "    sentence_index=sentence_index,\n",
    "    use_sentence_context=USE_SENTENCE_CONTEXT,\n",
    "    dry_run=DRY_RUN,\n",
    ")\n",
    "\n",
    "print(\"âœ“ Completed LLM reranking\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cad5e436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Saved reranked predictions to: c:\\Users\\super\\Documents\\UniPd\\ATA\\ATE-IT_SofiaMaule\\src\\predictions\\subtask_a_dev_ensemble_bert_2e-5_changed_reranked_llm.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 10. Save output\n",
    "\n",
    "OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(reranked_full, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"âœ“ Saved reranked predictions to: {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049c5459",
   "metadata": {},
   "source": [
    "## 11. Evaluate reranking with Micro / Type F1\n",
    "\n",
    "We now evaluate the **reranked LLM output** against the **gold dev annotations**, using the usual:\n",
    "\n",
    "- `micro_f1_score(...)`\n",
    "- `type_f1_score(...)`\n",
    "\n",
    "We assume those functions are already defined in the notebook (as you pasted).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9bf96cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Evaluation functions defined\n"
     ]
    }
   ],
   "source": [
    "def micro_f1_score(gold_standard, system_output):\n",
    "    \"\"\"\n",
    "    Evaluates performance using Precision, Recall, and F1 score \n",
    "    based on individual term matching (micro-average).\n",
    "    \"\"\"\n",
    "    total_true_positives = 0\n",
    "    total_false_positives = 0\n",
    "    total_false_negatives = 0\n",
    "    \n",
    "    for gold, system in zip(gold_standard, system_output):\n",
    "        gold_set = set(gold)\n",
    "        system_set = set(system)\n",
    "        \n",
    "        true_positives = len(gold_set.intersection(system_set))\n",
    "        false_positives = len(system_set - gold_set)\n",
    "        false_negatives = len(gold_set - system_set)\n",
    "        \n",
    "        total_true_positives += true_positives\n",
    "        total_false_positives += false_positives\n",
    "        total_false_negatives += false_negatives\n",
    "    \n",
    "    precision = total_true_positives / (total_true_positives + total_false_positives) if (total_true_positives + total_false_positives) > 0 else 0\n",
    "    recall = total_true_positives / (total_true_positives + total_false_negatives) if (total_true_positives + total_false_negatives) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1, total_true_positives, total_false_positives, total_false_negatives\n",
    "\n",
    "\n",
    "def type_f1_score(gold_standard, system_output):\n",
    "    \"\"\"\n",
    "    Evaluates performance using Type Precision, Type Recall, and Type F1 score\n",
    "    based on the set of unique terms extracted at least once across the entire dataset.\n",
    "    \"\"\"\n",
    "    all_gold_terms = set()\n",
    "    for item_terms in gold_standard:\n",
    "        all_gold_terms.update(item_terms)\n",
    "    \n",
    "    all_system_terms = set()\n",
    "    for item_terms in system_output:\n",
    "        all_system_terms.update(item_terms)\n",
    "    \n",
    "    type_true_positives = len(all_gold_terms.intersection(all_system_terms))\n",
    "    type_false_positives = len(all_system_terms - all_gold_terms)\n",
    "    type_false_negatives = len(all_gold_terms - all_system_terms)\n",
    "    \n",
    "    type_precision = type_true_positives / (type_true_positives + type_false_positives) if (type_true_positives + type_false_positives) > 0 else 0\n",
    "    type_recall = type_true_positives / (type_true_positives + type_false_negatives) if (type_true_positives + type_false_negatives) > 0 else 0\n",
    "    type_f1 = 2 * (type_precision * type_recall) / (type_precision + type_recall) if (type_precision + type_recall) > 0 else 0\n",
    "    \n",
    "    return type_precision, type_recall, type_f1\n",
    "\n",
    "\n",
    "print(\"âœ“ Evaluation functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d95fe044",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DEV_SENTENCES_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    gold_json = json.load(f)\n",
    "\n",
    "with open(OUTPUT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    reranked_json = json.load(f)\n",
    "\n",
    "with open(PREDICTIONS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    ensemble_json = json.load(f)\n",
    "\n",
    "gold_data = gold_json[\"data\"]\n",
    "reranked_data = reranked_json[\"data\"]\n",
    "ensemble_data = ensemble_json[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc1465aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Alignment OK for Ensemble vs Gold\n",
      "âœ“ Alignment OK for Reranked vs Gold\n"
     ]
    }
   ],
   "source": [
    "def check_alignment(gold, system, name: str):\n",
    "    if len(gold) != len(system):\n",
    "        raise ValueError(f\"[{name}] Length mismatch: gold={len(gold)}, system={len(system)}\")\n",
    "\n",
    "    for i, (g, s) in enumerate(zip(gold, system)):\n",
    "        g_key = (g[\"document_id\"], g[\"paragraph_id\"], g[\"sentence_id\"])\n",
    "        s_key = (s[\"document_id\"], s[\"paragraph_id\"], s[\"sentence_id\"])\n",
    "        if g_key != s_key:\n",
    "            raise ValueError(\n",
    "                f\"[{name}] ID mismatch at index {i}:\\n\"\n",
    "                f\"  gold   = {g_key}\\n\"\n",
    "                f\"  system = {s_key}\"\n",
    "            )\n",
    "\n",
    "    print(f\"âœ“ Alignment OK for {name}\")\n",
    "\n",
    "check_alignment(gold_data, ensemble_data, name=\"Ensemble vs Gold\")\n",
    "check_alignment(gold_data, reranked_data, name=\"Reranked vs Gold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c1360975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example gold terms     : ['disciplina dei centri di raccolta dei rifiuti urbani raccolti in modo differenziato', 'disciplinare per la gestione dei centri di raccolta comunali']\n",
      "Example ensemble terms : ['disciplinare per la gestione dei centri di raccolta comunali', 'centri di raccolta dei rifiuti urbani raccolti in']\n",
      "Example reranked terms : ['disciplinare per la gestione dei centri di raccolta comunali']\n"
     ]
    }
   ],
   "source": [
    "# Extract term lists (gold, ensemble, reranked)\n",
    "\n",
    "gold_terms = [entry.get(\"term_list\", []) for entry in gold_data]\n",
    "ensemble_terms = [entry.get(\"term_list\", []) for entry in ensemble_data]\n",
    "reranked_terms = [entry.get(\"term_list\", []) for entry in reranked_data]\n",
    "\n",
    "print(\"Example gold terms     :\", gold_terms[1][:5])\n",
    "print(\"Example ensemble terms :\", ensemble_terms[1][:5])\n",
    "print(\"Example reranked terms :\", reranked_terms[1][:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "39d217d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Ensemble (BERT + spaCy + dict) ===\n",
      "Micro Precision : 0.769\n",
      "Micro Recall    : 0.729\n",
      "Micro F1        : 0.749\n",
      "  TP / FP / FN  : 329 / 99 / 122\n",
      "\n",
      "Type Precision  : 0.728\n",
      "Type Recall     : 0.674\n",
      "Type F1         : 0.700\n"
     ]
    }
   ],
   "source": [
    "# Compute metrics for original ensemble baseline\n",
    "\n",
    "ens_p, ens_r, ens_f1, ens_tp, ens_fp, ens_fn = micro_f1_score(gold_terms, ensemble_terms)\n",
    "ens_tp_p, ens_tp_r, ens_tp_f1 = type_f1_score(gold_terms, ensemble_terms)\n",
    "\n",
    "print(\"=== Ensemble (BERT + spaCy + dict) ===\")\n",
    "print(f\"Micro Precision : {ens_p:.3f}\")\n",
    "print(f\"Micro Recall    : {ens_r:.3f}\")\n",
    "print(f\"Micro F1        : {ens_f1:.3f}\")\n",
    "print(f\"  TP / FP / FN  : {ens_tp} / {ens_fp} / {ens_fn}\")\n",
    "print()\n",
    "print(f\"Type Precision  : {ens_tp_p:.3f}\")\n",
    "print(f\"Type Recall     : {ens_tp_r:.3f}\")\n",
    "print(f\"Type F1         : {ens_tp_f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e16e1b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LLM Reranked (Groq) ===\n",
      "Micro Precision : 0.769\n",
      "Micro Recall    : 0.723\n",
      "Micro F1        : 0.745\n",
      "  TP / FP / FN  : 326 / 98 / 125\n",
      "\n",
      "Type Precision  : 0.730\n",
      "Type Recall     : 0.669\n",
      "Type F1         : 0.698\n"
     ]
    }
   ],
   "source": [
    "#  Compute metrics for LLM-reranked system\n",
    "\n",
    "llm_p, llm_r, llm_f1, llm_tp, llm_fp, llm_fn = micro_f1_score(gold_terms, reranked_terms)\n",
    "llm_tp_p, llm_tp_r, llm_tp_f1 = type_f1_score(gold_terms, reranked_terms)\n",
    "\n",
    "print(\"=== LLM Reranked (Groq) ===\")\n",
    "print(f\"Micro Precision : {llm_p:.3f}\")\n",
    "print(f\"Micro Recall    : {llm_r:.3f}\")\n",
    "print(f\"Micro F1        : {llm_f1:.3f}\")\n",
    "print(f\"  TP / FP / FN  : {llm_tp} / {llm_fp} / {llm_fn}\")\n",
    "print()\n",
    "print(f\"Type Precision  : {llm_tp_p:.3f}\")\n",
    "print(f\"Type Recall     : {llm_tp_r:.3f}\")\n",
    "print(f\"Type F1         : {llm_tp_f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32d341da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>micro_recall</th>\n",
       "      <th>micro_f1</th>\n",
       "      <th>type_precision</th>\n",
       "      <th>type_recall</th>\n",
       "      <th>type_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ensemble</td>\n",
       "      <td>0.768692</td>\n",
       "      <td>0.729490</td>\n",
       "      <td>0.748578</td>\n",
       "      <td>0.727679</td>\n",
       "      <td>0.673554</td>\n",
       "      <td>0.699571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llm_reranked</td>\n",
       "      <td>0.768868</td>\n",
       "      <td>0.722838</td>\n",
       "      <td>0.745143</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.669421</td>\n",
       "      <td>0.698276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model  micro_precision  micro_recall  micro_f1  type_precision  \\\n",
       "0      ensemble         0.768692      0.729490  0.748578        0.727679   \n",
       "1  llm_reranked         0.768868      0.722838  0.745143        0.729730   \n",
       "\n",
       "   type_recall   type_f1  \n",
       "0     0.673554  0.699571  \n",
       "1     0.669421  0.698276  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compact comparison summary\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "summary = pd.DataFrame(\n",
    "    [\n",
    "        [\"ensemble\", ens_p, ens_r, ens_f1, ens_tp_p, ens_tp_r, ens_tp_f1],\n",
    "        [\"llm_reranked\", llm_p, llm_r, llm_f1, llm_tp_p, llm_tp_r, llm_tp_f1],\n",
    "    ],\n",
    "    columns=[\n",
    "        \"model\",\n",
    "        \"micro_precision\",\n",
    "        \"micro_recall\",\n",
    "        \"micro_f1\",\n",
    "        \"type_precision\",\n",
    "        \"type_recall\",\n",
    "        \"type_f1\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e80086",
   "metadata": {},
   "source": [
    "## 11. Next steps and tuning ideas\n",
    "\n",
    "Some ideas to improve the reranking quality:\n",
    "\n",
    "1. **Adjust the prompt**:\n",
    "   - Be more strict or more permissive in the instructions.\n",
    "   - Emphasize multi-word terms or certain POS patterns.\n",
    "\n",
    "2. **Control filtering**:\n",
    "   - After reranking, you can:\n",
    "     - Keep only the top-K terms per sentence (e.g., top 3 or top 5).\n",
    "     - Discard terms with score `< 0.4` (or another threshold).\n",
    "\n",
    "3. **Domain-specific heuristics**:\n",
    "   - Penalize candidates that end with stopwords like *\"di\"*, *\"dei\"*, *\"e\"*, etc.\n",
    "   - Boost terms that include frequent domain keywords (*\"rifiuti\"*, *\"raccolta\"*, *\"centro di raccolta\"*, etc.).\n",
    "\n",
    "You can implement these as a post-processing step on `reranked_full[\"data\"]` before saving, or directly instruct the LLM in the prompt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b942da",
   "metadata": {},
   "source": [
    "## ADVANCED DEBUG ANALYSIS FOR RERANKING QUALITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "969f1f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DEBUG ANALYSIS START ===\n",
      "\n",
      "âœ“ Debug dataframe created\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=== DEBUG ANALYSIS START ===\\n\")\n",
    "\n",
    "debug_rows = []\n",
    "\n",
    "for i, (gold, ens, rer) in enumerate(zip(gold_terms, ensemble_terms, reranked_terms)):\n",
    "\n",
    "    gold_set = set(gold)\n",
    "    ens_set = set(ens)\n",
    "    rer_set = set(rer)\n",
    "\n",
    "    lost_terms = list(ens_set - rer_set)\n",
    "    added_terms = list(rer_set - ens_set)\n",
    "\n",
    "    false_positives = list(rer_set - gold_set)\n",
    "    true_positives = list(rer_set & gold_set)\n",
    "    new_true_positives = list((rer_set - ens_set) & gold_set)\n",
    "\n",
    "    hard_missed = list(gold_set - ens_set - rer_set)\n",
    "\n",
    "    debug_rows.append({\n",
    "        \"index\": i,\n",
    "        \"gold\": gold,\n",
    "        \"ensemble\": ens,\n",
    "        \"reranked\": rer,\n",
    "        \"lost_terms\": lost_terms,\n",
    "        \"added_terms\": added_terms,\n",
    "        \"remaining_false_positives\": false_positives,\n",
    "        \"new_true_positives\": new_true_positives,\n",
    "        \"hard_missed_terms\": hard_missed,\n",
    "    })\n",
    "\n",
    "df_debug = pd.DataFrame(debug_rows)\n",
    "print(\"âœ“ Debug dataframe created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290989ec",
   "metadata": {},
   "source": [
    "### Lost terms during reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "402b9e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TOP LOST TERMS (reranking removed them but they were in ensemble) ===\n",
      "centri di raccolta dei rifiuti urbani raccolti in  â†’  removed 1 times\n",
      "differenziati                             â†’  removed 1 times\n",
      "ccr                                       â†’  removed 1 times\n",
      "rup                                       â†’  removed 1 times\n"
     ]
    }
   ],
   "source": [
    "lost_counter = Counter(\n",
    "    t for row in debug_rows for t in row[\"lost_terms\"]\n",
    ")\n",
    "\n",
    "print(\"\\n=== TOP LOST TERMS (reranking removed them but they were in ensemble) ===\")\n",
    "for term, count in lost_counter.most_common(20):\n",
    "    print(f\"{term:40s}  â†’  removed {count} times\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24737584",
   "metadata": {},
   "source": [
    "### added terms with reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7b117070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TERMS ADDED BY RERANKING (not in ensemble) ===\n"
     ]
    }
   ],
   "source": [
    "added_counter = Counter(\n",
    "    t for row in debug_rows for t in row[\"added_terms\"]\n",
    ")\n",
    "\n",
    "print(\"\\n=== TERMS ADDED BY RERANKING (not in ensemble) ===\")\n",
    "for term, count in added_counter.most_common(20):\n",
    "    print(f\"{term:40s}  â†’  added {count} times\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a100c9",
   "metadata": {},
   "source": [
    "### False positives rimasti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a4bf2b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== REMAINING FALSE POSITIVES (still wrong after reranking) ===\n",
      "plastica                                  â†’  FP 4 times\n",
      "alluminio                                 â†’  FP 3 times\n",
      "rifiuti                                   â†’  FP 3 times\n",
      "carta                                     â†’  FP 2 times\n",
      "centro di raccolta                        â†’  FP 2 times\n",
      "acciaio                                   â†’  FP 2 times\n",
      "depositare                                â†’  FP 2 times\n",
      "svuotamento                               â†’  FP 2 times\n",
      "utenti                                    â†’  FP 2 times\n",
      "raccolta differenziata                    â†’  FP 2 times\n",
      "sacco azzurro                             â†’  FP 2 times\n",
      "metallo                                   â†’  FP 2 times\n",
      "banda stagnata                            â†’  FP 2 times\n",
      "servizio di raccolta dei rifiuti derivanti  â†’  FP 1 times\n",
      "tessuto                                   â†’  FP 1 times\n",
      "utenze domestiche                         â†’  FP 1 times\n",
      "cartoni                                   â†’  FP 1 times\n",
      "vanno conferiti                           â†’  FP 1 times\n",
      "scarti e avanzi                           â†’  FP 1 times\n",
      "materiali finiti                          â†’  FP 1 times\n"
     ]
    }
   ],
   "source": [
    "fp_counter = Counter(\n",
    "    t for row in debug_rows for t in row[\"remaining_false_positives\"]\n",
    ")\n",
    "\n",
    "print(\"\\n=== REMAINING FALSE POSITIVES (still wrong after reranking) ===\")\n",
    "for term, count in fp_counter.most_common(20):\n",
    "    print(f\"{term:40s}  â†’  FP {count} times\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6596042",
   "metadata": {},
   "source": [
    "### true positives added with reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3b69b388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TRUE POSITIVES ADDED BY RERANKING (good improvements) ===\n"
     ]
    }
   ],
   "source": [
    "tp_gain_counter = Counter(\n",
    "    t for row in debug_rows for t in row[\"new_true_positives\"]\n",
    ")\n",
    "\n",
    "print(\"\\n=== TRUE POSITIVES ADDED BY RERANKING (good improvements) ===\")\n",
    "for term, count in tp_gain_counter.most_common(20):\n",
    "    print(f\"{term:40s}  â†’  NEW TP {count} times\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94bf5c1",
   "metadata": {},
   "source": [
    "### Hard cases (termini gold mancanti sia da ensemble che reranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "33c76146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== HARD MISSED TERMS (neither ensemble nor reranking found them) ===\n",
      "sacchetto trasparente                     â†’  MISSED 4 times\n",
      "raccolta                                  â†’  MISSED 3 times\n",
      "conferiti                                 â†’  MISSED 3 times\n",
      "plastica                                  â†’  MISSED 3 times\n",
      "frazione verde                            â†’  MISSED 2 times\n",
      "conferimento                              â†’  MISSED 2 times\n",
      "modalitÃ  di conferimento                  â†’  MISSED 2 times\n",
      "rifiuti                                   â†’  MISSED 2 times\n",
      "busta con legaccio                        â†’  MISSED 2 times\n",
      "misure di gestione ambientale             â†’  MISSED 2 times\n",
      "r.a.e.e.                                  â†’  MISSED 2 times\n",
      "conferire                                 â†’  MISSED 2 times\n",
      "tari                                      â†’  MISSED 2 times\n",
      "modalitÃ  di raccolta                      â†’  MISSED 2 times\n",
      "sacco                                     â†’  MISSED 2 times\n",
      "disciplina dei centri di raccolta dei rifiuti urbani raccolti in modo differenziato  â†’  MISSED 1 times\n",
      "gestione del centro di raccolta           â†’  MISSED 1 times\n",
      "pile portatili, batterie e accumulatori al piombo derivanti dalla manutenzione di veicoli ad uso privato effettuata in proprio dalle utenze domestiche  â†’  MISSED 1 times\n",
      "ritiro                                    â†’  MISSED 1 times\n",
      "plastica, acciaio e alluminio             â†’  MISSED 1 times\n"
     ]
    }
   ],
   "source": [
    "hard_counter = Counter(\n",
    "    t for row in debug_rows for t in row[\"hard_missed_terms\"]\n",
    ")\n",
    "\n",
    "print(\"\\n=== HARD MISSED TERMS (neither ensemble nor reranking found them) ===\")\n",
    "for term, count in hard_counter.most_common(20):\n",
    "    print(f\"{term:40s}  â†’  MISSED {count} times\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0e92c876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SENTENCES WHERE RERANKING LOST MOST TERMS ===\n",
      "\n",
      "=== SENTENCES WHERE RERANKING HAS MOST FALSE POSITIVES ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>remaining_false_positives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>[plastica, alluminio, cartoni, acciaio, vanno ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>371</td>\n",
       "      <td>[lattine, metallo, alluminio, banda stagnata]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>402</td>\n",
       "      <td>[recupero, oli conferiti, oli esausti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>569</td>\n",
       "      <td>[acciaio, banda stagnata, alluminio]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>576</td>\n",
       "      <td>[metallo, sacco azzurro, rifiuti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>285</td>\n",
       "      <td>[gestori, centro di raccolta differenziata]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>154</td>\n",
       "      <td>[carrellati condomini, svuotamento]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>272</td>\n",
       "      <td>[ferro, rifiuti raccolti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>121</td>\n",
       "      <td>[operatori, isola ecologica]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>[sito, frazioni di rifiuti]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                          remaining_false_positives\n",
       "50      50  [plastica, alluminio, cartoni, acciaio, vanno ...\n",
       "371    371      [lattine, metallo, alluminio, banda stagnata]\n",
       "402    402             [recupero, oli conferiti, oli esausti]\n",
       "569    569               [acciaio, banda stagnata, alluminio]\n",
       "576    576                  [metallo, sacco azzurro, rifiuti]\n",
       "285    285        [gestori, centro di raccolta differenziata]\n",
       "154    154                [carrellati condomini, svuotamento]\n",
       "272    272                          [ferro, rifiuti raccolti]\n",
       "121    121                       [operatori, isola ecologica]\n",
       "199    199                        [sito, frazioni di rifiuti]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentences where LLM made the worst damage:\n",
    "df_debug[\"lost_count\"] = df_debug[\"lost_terms\"].apply(len)\n",
    "df_debug[\"fp_count\"] = df_debug[\"remaining_false_positives\"].apply(len)\n",
    "\n",
    "worst_lost = df_debug.sort_values(\"lost_count\", ascending=False).head(10)\n",
    "worst_fp = df_debug.sort_values(\"fp_count\", ascending=False).head(10)\n",
    "\n",
    "print(\"\\n=== SENTENCES WHERE RERANKING LOST MOST TERMS ===\")\n",
    "worst_lost[[\"index\", \"lost_terms\"]]\n",
    "\n",
    "print(\"\\n=== SENTENCES WHERE RERANKING HAS MOST FALSE POSITIVES ===\")\n",
    "worst_fp[[\"index\", \"remaining_false_positives\"]]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
