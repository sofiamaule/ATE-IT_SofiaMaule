{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7bef84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import List, Dict, Tuple\n",
    "from collections import Counter\n",
    "\n",
    "PRED_FILE = \"predictions/subtask_a_test_ensemble_bert_spacy_dictfilter_submission.json\"\n",
    "\n",
    "def load_json(path: str):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e8a02b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading predictions from: predictions/subtask_a_test_ensemble_bert_spacy_dictfilter_submission.json\n",
      "\n",
      "=== SUBMISSION CONSTRAINTS CHECK ===\n",
      "Total sentences: 1142\n",
      "Total terms:     630\n",
      "\n",
      "1) LOWERCASE CHECK\n",
      "  Sentences with non-lowercase terms: 0\n",
      "  Total non-lowercase terms:          0\n",
      "\n",
      "2) DUPLICATES CHECK\n",
      "  Sentences with duplicate terms: 0\n",
      "  Total duplicate term types:     0\n",
      "\n",
      "3) NESTED TERMS CHECK\n",
      "  Sentences with nested pairs: 0\n",
      "  Total nested pairs:          0\n",
      "\n",
      "=== SUMMARY ===\n",
      "The file satisfies all output constraints.\n"
     ]
    }
   ],
   "source": [
    "def load_json(path: str):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "\n",
    "def is_lowercase(term: str) -> bool:\n",
    "    return term == term.lower()\n",
    "\n",
    "\n",
    "def has_duplicates(terms: List[str]) -> bool:\n",
    "    return len(terms) != len(set(terms))\n",
    "\n",
    "\n",
    "def contains_as_subspan(longer: str, shorter: str) -> bool:\n",
    "    \"\"\"\n",
    "    shorter è 'nested' in longer se i token di shorter compaiono\n",
    "    come sottosequenza contigua dei token di longer.\n",
    "    Esempio:\n",
    "      longer = \"impianto di trattamento rifiuti\"\n",
    "      shorter = \"trattamento rifiuti\"  --> True\n",
    "    \"\"\"\n",
    "    long_tokens = longer.split()\n",
    "    short_tokens = shorter.split()\n",
    "    L, S = len(long_tokens), len(short_tokens)\n",
    "    if S >= L:\n",
    "        return False\n",
    "    for i in range(L - S + 1):\n",
    "        if long_tokens[i:i+S] == short_tokens:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def find_nested_pairs(terms: List[str]) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Ritorna lista di coppie (shorter, longer) che sono nested\n",
    "    all'interno della stessa sentence.\n",
    "    \"\"\"\n",
    "    nested = []\n",
    "    for i, t1 in enumerate(terms):\n",
    "        for j, t2 in enumerate(terms):\n",
    "            if i == j:\n",
    "                continue\n",
    "            # t1 potenziale \"shorter\", t2 potenziale \"longer\"\n",
    "            if contains_as_subspan(t2, t1):\n",
    "                nested.append((t1, t2))\n",
    "    return nested\n",
    "\n",
    "\n",
    "\n",
    "def check_submission(pred_path: str):\n",
    "    print(f\"Loading predictions from: {pred_path}\")\n",
    "    pred = load_json(pred_path)\n",
    "    rows = pred[\"data\"] if isinstance(pred, dict) and \"data\" in pred else pred\n",
    "\n",
    "    stats = Counter()\n",
    "    lower_violations_examples = []\n",
    "    dup_violations_examples = []\n",
    "    nested_violations_examples = []\n",
    "\n",
    "    for idx, entry in enumerate(rows):\n",
    "        terms: List[str] = entry.get(\"term_list\", []) or []\n",
    "\n",
    "        # 1) check lowercase\n",
    "        not_lower = [t for t in terms if not is_lowercase(t)]\n",
    "        if not_lower:\n",
    "            stats[\"sentences_not_lower\"] += 1\n",
    "            stats[\"terms_not_lower\"] += len(not_lower)\n",
    "            if len(lower_violations_examples) < 5:\n",
    "                lower_violations_examples.append({\n",
    "                    \"index\": idx,\n",
    "                    \"doc\": entry[\"document_id\"],\n",
    "                    \"paragraph_id\": entry[\"paragraph_id\"],\n",
    "                    \"sentence_id\": entry[\"sentence_id\"],\n",
    "                    \"bad_terms\": not_lower,\n",
    "                })\n",
    "\n",
    "        # 2) check duplicates\n",
    "        if has_duplicates(terms):\n",
    "            seen = set()\n",
    "            dups = []\n",
    "            for t in terms:\n",
    "                if t in seen and t not in dups:\n",
    "                    dups.append(t)\n",
    "                seen.add(t)\n",
    "            stats[\"duplicate_terms_total\"] += len(dups)\n",
    "            if len(dup_violations_examples) < 5:\n",
    "                dup_violations_examples.append({\n",
    "                    \"index\": idx,\n",
    "                    \"doc\": entry[\"document_id\"],\n",
    "                    \"paragraph_id\": entry[\"paragraph_id\"],\n",
    "                    \"sentence_id\": entry[\"sentence_id\"],\n",
    "                    \"duplicate_terms\": dups,\n",
    "                })\n",
    "\n",
    "        # 3) check nested terms\n",
    "        nested_pairs = find_nested_pairs(terms)\n",
    "        if nested_pairs:\n",
    "            stats[\"sentences_with_nested\"] += 1\n",
    "            stats[\"nested_pairs_total\"] += len(nested_pairs)\n",
    "            if len(nested_violations_examples) < 5:\n",
    "                nested_violations_examples.append({\n",
    "                    \"index\": idx,\n",
    "                    \"doc\": entry[\"document_id\"],\n",
    "                    \"paragraph_id\": entry[\"paragraph_id\"],\n",
    "                    \"sentence_id\": entry[\"sentence_id\"],\n",
    "                    \"nested_pairs\": nested_pairs,\n",
    "                })\n",
    "\n",
    "        stats[\"total_sentences\"] += 1\n",
    "        stats[\"total_terms\"] += len(terms)\n",
    "\n",
    "    # ========= REPORT =========\n",
    "    print(\"\\n=== SUBMISSION CONSTRAINTS CHECK ===\")\n",
    "    print(f\"Total sentences: {stats['total_sentences']}\")\n",
    "    print(f\"Total terms:     {stats['total_terms']}\")\n",
    "\n",
    "    print(\"\\n1) LOWERCASE CHECK\")\n",
    "    print(f\"  Sentences with non-lowercase terms: {stats['sentences_not_lower']}\")\n",
    "    print(f\"  Total non-lowercase terms:          {stats['terms_not_lower']}\")\n",
    "    if lower_violations_examples:\n",
    "        print(\"  Examples:\")\n",
    "        for ex in lower_violations_examples:\n",
    "            print(f\"    - idx={ex['index']} ({ex['doc']}, p{ex['paragraph_id']}, s{ex['sentence_id']}): {ex['bad_terms']}\")\n",
    "\n",
    "    print(\"\\n2) DUPLICATES CHECK\")\n",
    "    print(f\"  Sentences with duplicate terms: {stats['sentences_with_duplicates']}\")\n",
    "    print(f\"  Total duplicate term types:     {stats['duplicate_terms_total']}\")\n",
    "    if dup_violations_examples:\n",
    "        print(\"  Examples:\")\n",
    "        for ex in dup_violations_examples:\n",
    "            print(f\"    - idx={ex['index']} ({ex['doc']}, p{ex['paragraph_id']}, s{ex['sentence_id']}): {ex['duplicate_terms']}\")\n",
    "\n",
    "    print(\"\\n3) NESTED TERMS CHECK\")\n",
    "    print(f\"  Sentences with nested pairs: {stats['sentences_with_nested']}\")\n",
    "    print(f\"  Total nested pairs:          {stats['nested_pairs_total']}\")\n",
    "    if nested_violations_examples:\n",
    "        print(\"  Examples:\")\n",
    "        for ex in nested_violations_examples:\n",
    "            print(f\"    - idx={ex['index']} ({ex['doc']}, p{ex['paragraph_id']}, s{ex['sentence_id']}):\")\n",
    "            for shorter, longer in ex[\"nested_pairs\"]:\n",
    "                print(f\"        '{shorter}' ⊂ '{longer}'\")\n",
    "\n",
    "    print(\"\\n=== SUMMARY ===\")\n",
    "    if stats[\"sentences_not_lower\"] == 0 and stats[\"sentences_with_duplicates\"] == 0 and stats[\"sentences_with_nested\"] == 0:\n",
    "        print(\"The file satisfies all output constraints.\")\n",
    "    else:\n",
    "        print(\"There are violations of the constraints above. Fix before submission.\")\n",
    "\n",
    "\n",
    "# ========= RUN =========\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_submission(PRED_FILE)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ATE-IT venv)",
   "language": "python",
   "name": "ate-it-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
